{{about|cognition|other uses|Consciousness (disambiguation)}}
{{Redirect|Conscious|Broods' second album|Conscious (album)}}
{{good article}}
[[Image:RobertFuddBewusstsein17Jh.png|thumb|Representation of consciousness from the seventeenth century]]
'''Consciousness''' is the state or [[Quality (philosophy)|quality]] of awareness, or, of being [[awareness|aware]] of an external object or something within oneself.<ref>{{cite web|title=consciousness|publisher=Merriam-Webster|location=|accessdate=June 4, 2012|url= http://www.merriam-webster.com/dictionary/consciousness}}</ref><ref name="van_Gulick2004">{{cite web |author=Robert van Gulick |year=2004 |title=Consciousness |publisher=Stanford Encyclopedia of Philosophy |url=http://plato.stanford.edu/entries/consciousness/}}</ref> It has been defined as: [[sentience]], [[awareness]], [[subjectivity]], the ability to [[experience]] or to  [[feeling|feel]], [[wakefulness]], having a sense of [[self]]hood, and the executive control system of the [[mind]].<ref name=Farthing1992Psychology>{{cite book| title=The Psychology of Consciousness |author=Farthing G |year=1992 |publisher=Prentice Hall |isbn=978-0-13-728668-3}}</ref> Despite the difficulty in definition, many philosophers believe that there is a broadly shared underlying intuition about what consciousness is.<ref>{{cite book |author=[[John Searle]] |year=2005 |editor=Honderich T |title=The Oxford companion to philosophy |chapter=Consciousness |publisher=Oxford University Press |isbn=978-0-19-926479-7}}</ref> As [[Max Velmans]] and Susan Schneider wrote in ''The Blackwell Companion to Consciousness'': "Anything that we are aware of at a given moment forms part of our consciousness, making conscious experience at once the most familiar and most mysterious aspect of our lives."<ref>{{cite book |authors=Susan Schneider and [[Max Velmans]] |year=2008 |chapter=Introduction |editors=Max Velmans, Susan Schneider |title=The Blackwell Companion to Consciousness |publisher=Wiley |isbn=978-0-470-75145-9}}</ref>

Western [[philosophy|philosophers]], since the time of [[René Descartes|Descartes]] and [[John Locke|Locke]], have struggled to comprehend the nature of consciousness and identify its essential properties.  Issues of concern in the philosophy of consciousness include whether the concept is fundamentally coherent; whether consciousness can ever be explained [[mechanism (philosophy)|mechanistically]]; whether [[non-human]] consciousness exists and if so how can it be recognized; how consciousness relates to [[language]]; whether consciousness can be understood in a way that does not require a [[dualism (philosophy of mind)|dualistic]] distinction between mental and physical states or properties; and whether it may ever be possible for computing machines like [[computer]]s or [[robot]]s to be conscious, a topic studied in the field of [[artificial intelligence]].

Thanks to recent developments in technology, consciousness has become a significant topic of research in [[psychology]], [[neuropsychology]] and [[neuroscience]] within the past few decades.  The primary focus is on understanding what it means biologically and psychologically for [[information]] to be present in consciousness—that is, on determining the neural and psychological correlates of consciousness.  The majority of experimental studies assess consciousness by asking human subjects for a verbal report of their experiences (e.g., "tell me if you notice anything when I do this").  Issues of interest include phenomena such as [[subliminal stimuli|subliminal perception]], [[blindsight]], [[anosognosia|denial of impairment]], and [[altered state of consciousness|altered states of consciousness]] produced by alcohol and other drugs, or spiritual or meditative techniques.

In [[medicine]], consciousness is assessed by observing a patient's arousal and responsiveness, and can be seen as a continuum of states ranging from full alertness and comprehension, through disorientation, delirium, loss of meaningful communication, and finally loss of movement in response to painful [[Stimulus (physiology)|stimuli]].<ref>{{cite book |authors=Güven Güzeldere |title=The Nature of Consciousness: Philosophical debates |year=1997 |editors=Ned Block, Owen Flanagan, Güven Güzeldere |pages=1–67 |location=Cambridge, MA |publisher=MIT Press}}</ref>  Issues of practical concern include how the presence of consciousness can be assessed in severely ill, comatose, or anesthetized people, and how to treat conditions in which consciousness is impaired or disrupted.<ref>{{cite journal |title=Late recovery from the minimally conscious state: ethical and policy implications |authors=J. J. Fins, N. D. Schiff, and K. M. Foley |journal=Neurology |year=2007 |volume=68 |pages=304–307 |pmid=17242341 |doi=10.1212/01.wnl.0000252376.43779.96 |issue=4}}</ref>

{{TOC limit}}

==Etymology and early history==
[[File:JohnLocke.png|thumb|right|150px|[[John Locke]], British philosopher active in the 17th century]]
The origin of the modern concept of consciousness is often attributed to [[John Locke]]'s ''[[Essay Concerning Human Understanding]]'', published in 1690.<ref>{{cite web|title=An Essay Concerning Human Understanding (Chapter XXVII)|last=Locke|first=John|publisher=University of Adelaide|location=Australia|url=http://ebooks.adelaide.edu.au/l/locke/john/l81u/B2.27.html|accessdate=August 20, 2010}}</ref>  Locke defined consciousness as "the perception of what passes in a man's own mind".<ref>{{cite web|url=http://www.britannica.com/EBchecked/topic/133274/consciousness|title=Science & Technology: consciousness|publisher=Encyclopædia Britannica|accessdate=August 20, 2010}}</ref> His essay influenced the 18th-century view of consciousness, and his definition appeared in [[Samuel Johnson]]'s celebrated ''[[A Dictionary of the English Language|Dictionary]]'' (1755).<ref>{{cite book|title=A Dictionary of the English Language |authors=[[Samuel Johnson]] |publisher=Knapton |year=1756 |url=https://books.google.com/books?id=fcVEAAAAcAAJ}}</ref>
"Consciousness" (French: ''conscience'') is also defined in the 1753 volume of Diderot and d'Alembert's [[Encyclopédie]], as "the opinion or internal feeling that we ourselves have from what we do." <ref>Jaucourt, Louis, chevalier de. "Consciousness." The Encyclopedia of Diderot & d'Alembert Collaborative Translation Project. Translated by Scott St. Louis. Ann Arbor: Michigan Publishing, University of Michigan Library, 2014. http://hdl.handle.net/2027/spo.did2222.0002.986. Originally published as "Conscience," Encyclopédie ou Dictionnaire raisonné des sciences, des arts et des métiers, 3:902 (Paris, 1753).</ref>

The earliest English language uses of "conscious" and "consciousness" date back, however, to the 1500s.  The English word "conscious" originally derived from the Latin ''conscius'' (''con-'' "together" and [[wikt:scio|''scio'']] "to know"), but the Latin word did not have the same meaning as our word—it meant "knowing with", in other words "having joint or common [[knowledge]] with another".<ref>{{cite book |title=Studies in words |author =[[C. S. Lewis]]|year=1990 |publisher=Cambridge University Press |chapter=Ch. 8: Conscience and conscious |isbn=978-0-521-39831-2}}</ref>  There were, however, many occurrences in Latin writings of the phrase ''conscius sibi'', which translates literally as "knowing with oneself", or in other words "sharing knowledge with oneself about something".  This phrase had the figurative meaning of "knowing that one knows", as the modern English word "conscious" does.  In its earliest uses in the 1500s, the English word "conscious" retained the meaning of the Latin ''conscius''.  For example, [[Thomas Hobbes]] in ''[[Leviathan (book)|Leviathan]]'' wrote: "Where two, or more men, know of one and the same fact, they are said to be Conscious of it one to another."<ref>{{cite book|title=Leviathan: or, The Matter, Forme & Power of a Commonwealth, Ecclesiasticall and Civill |author=[[Thomas Hobbes]] |publisher=University Press |year=1904 |url=https://books.google.com/books?id=2oc6AAAAMAAJ |page=39}}</ref>  The Latin phrase ''conscius sibi'', whose meaning was more closely related to the current concept of consciousness, was rendered in English as "conscious to oneself" or "conscious unto oneself".  For example, [[Archbishop Ussher]] wrote in 1613 of "being so conscious unto myself of my great weakness".<ref>{{cite book |title=The whole works, Volume 2 |author=[[James Ussher]], [[Charles Richard Elrington]] |page=417 |year=1613 |publisher=Hodges and Smith}}</ref>  Locke's definition from 1690 illustrates that a gradual shift in meaning had taken place.

A related word was ''[[:la:conscientia|conscientia]]'', which primarily means [[morality|moral]] [[conscience]]. In the literal sense, "conscientia" means knowledge-with, that is, shared knowledge. The word first appears in Latin juridical texts by writers such as [[Cicero]].<ref>{{cite book|title= Dictionary of Untranslatables. A Philosophical Lexicon| authors=Barbara Cassin |publisher=Princeton University Press| isbn=978-0-691-13870-1| year=2014|page=176}}</ref> Here, ''conscientia'' is the knowledge that a witness has of the deed of someone else.<ref>{{cite journal| author=G. Molenaar|title=Seneca's Use of the Term Conscientia|journal=Mnemosyne| volume=22|year=1969|pages=170–180|doi=10.1163/156852569x00670}}</ref> [[René Descartes]] (1596–1650) is generally taken to be the first philosopher to use ''conscientia'' in a way that does not fit this traditional meaning.<ref>{{cite journal| author=Boris Hennig |title=Cartesian Conscientia|journal=British Journal for the History of Philosophy |year=2007 |volume=15 |pages=455–484 |doi=10.1080/09608780701444915}}</ref> Descartes used ''conscientia'' the way modern speakers would use "conscience".  In ''Search after Truth'' (''{{lang|la|Regulæ ad directionem ingenii ut et inquisitio veritatis per lumen naturale}}'', Amsterdam 1701) he says "conscience or internal testimony" (''conscientiâ, vel interno testimonio'').<ref>Charles Adam, [[Paul Tannery]] (eds.), ''Oeuvres de Descartes'' X, [https://archive.org/stream/oeuvresdedescar10desc#page/524/mode/2up 524] (1908).</ref><ref>{{cite book |pages=205–206 |title=Consciousness: from perception to reflection in the history of philosophy |isbn=978-1-4020-6081-6 |publisher=Springer |author=Sara Heinämaa, Vili Lähteenmäki, Pauliina Remes (eds.) |year=2007}}</ref>

==In the dictionary==
{{Format|date=October 2016}}
The dictionary meaning of the word ''consciousness'' extends through several centuries and associated cognate meanings which have ranged from formal definitions to somewhat more skeptical definitions. One formal definition indicating the range of these cognate meanings is given in ''[[Webster's Third New International Dictionary]]'' stating that ''consciousness'' is: "(1) ''a.'' awareness or perception of an inward psychological or spiritual fact: intuitively perceived knowledge of something in one's inner self. ''b.'' inward awareness of an external object, state, or fact. ''c.'' concerned awareness: INTEREST, CONCERN -- often used with an attributive noun. (2): the state or activity that is characterized by sensation, emotion, volition, or thought: mind in the broadest possible sense: something in nature that is distinguished from the physical. (3): the totality in psychology of sensations, perceptions, ideas, attitudes and feelings of which an individual or a group is aware at any given time or within a particular time span -- compare STREAM OF CONSCIOUSNESS."

==Philosophy of mind==
The [[philosophy of mind]] has given rise to many stances regarding consciousness. The ''[[Routledge Encyclopedia of Philosophy]]'' in 1998 defines consciousness as follows:

{{quote|'''Consciousness'''—Philosophers have used the term 'consciousness' for four main topics: knowledge in general, intentionality, introspection (and the knowledge it specifically generates) and phenomenal experience... Something within one's mind is 'introspectively conscious' just in case one introspects it (or is poised to do so). Introspection is often thought to deliver one's primary knowledge of one's mental life. An experience or other mental entity is 'phenomenally conscious' just in case there is 'something it is like' for one to have it. The clearest examples are: perceptual experience, such as tastings and seeings; bodily-sensational experiences, such as those of pains, tickles and itches; imaginative experiences, such as those of one's own actions or perceptions; and streams of thought, as in the experience of thinking 'in words' or 'in images'. Introspection and phenomenality seem independent, or dissociable, although this is controversial.<ref name=Craig>{{cite book |author=[[Edward Craig (philosopher)|Edward Craig]] |title=Routledge Encyclopedia of Philosophy |publisher=Routledge |chapter=Consciousness |year=1998 |isbn=0415-18707-9}}</ref>}}

In a more skeptical definition of ''consciousness'', [[Stuart Sutherland]] has exemplified some of the difficulties in fully ascertaining all of its cognate meanings in his entry for the 1989 version of the ''Macmillan Dictionary of Psychology'':

{{quote|'''Consciousness'''—The having of perceptions, thoughts, and feelings; awareness. The term is impossible to define except in terms that are unintelligible without a grasp of what consciousness means.  Many fall into the trap of equating consciousness with self-consciousness—to be conscious it is only necessary to be aware of the external world. Consciousness is a fascinating but elusive phenomenon: it is impossible to specify what it is, what it does, or why it has evolved. Nothing worth reading has been written on it.<ref name=Sutherland>{{cite book |author=[[Stuart Sutherland]] |title=Macmillan Dictionary of Psychology |publisher=Macmillan |chapter=Consciousness |year=1989 |isbn=978-0-333-38829-7}}</ref>}}

Most writers on the philosophy of consciousness have been concerned with defending a particular point of view, and have organized their material accordingly.  For surveys, the most common approach is to follow a historical path by associating stances with the philosophers who are most strongly associated with them, for example Descartes, Locke, Kant, etc. An alternative is to organize philosophical stances according to basic issues.

===The coherence of the concept===
Philosophers and non-philosophers differ in their intuitions about what consciousness is.<ref>{{cite journal |authors=Justin Sytsma and Edouard Machery |title=Two conceptions of subjective experience |journal=Philosophical Studies |year=2010 |volume=151 |pages=299–327 |doi=10.1007/s11098-009-9439-x}}</ref> While most people have a strong intuition for the existence of what they refer to as consciousness,<ref name=Antony2001>{{cite journal |author=Michael V. Antony |title=Is ''consciousness'' ambiguous? |journal=Journal of Consciousness Studies |volume=8 |year=2001 |pages=19–44}}</ref> skeptics argue that this intuition is false, either because the concept of consciousness is intrinsically incoherent, or because our intuitions about it are based in illusions.  [[Gilbert Ryle]], for example, argued that traditional understanding of consciousness depends on a [[dualism (philosophy of mind)|Cartesian dualist]] outlook that improperly distinguishes between mind and body, or between mind and world. He proposed that we speak not of minds, bodies, and the world, but of individuals, or persons, acting in the world. Thus, by speaking of "consciousness" we end up misleading ourselves by thinking that there is any sort of thing as consciousness separated from behavioral and linguistic understandings.<ref name=RyleConsciousness>{{cite book|title=[[The Concept of Mind]] |author=[[Gilbert Ryle]] |publisher=University of Chicago Press |year=1949 |pages=156–163|isbn=978-0-226-73296-1}}</ref>  More generally, many philosophers and scientists have been unhappy about the difficulty of producing a definition that does not involve circularity or fuzziness.<ref name=Sutherland/>

===Types of consciousness===
Many philosophers have argued that consciousness is a unitary concept that is understood intuitively by the majority of people in spite of the difficulty in defining it.<ref name="Antony2001"/>  Others, though, have argued that the level of disagreement about the meaning of the word indicates that it either means different things to different people (for instance, the [[Objectivity (philosophy)|objective]] versus [[Subjectivism|subjective]] aspects of consciousness), or else is an [[umbrella term]] encompassing a variety of distinct meanings with no simple element in common.<ref name=Velmans2009>{{cite journal |author=[[Max Velmans]] |title=How to define consciousness—and how not to define consciousness |journal=Journal of Consciousness Studies |year=2009 |volume=16 |pages=139–156}}</ref>

[[Ned Block]] proposed a distinction between two types of consciousness that he called ''phenomenal'' (P-consciousness) and ''access'' (A-consciousness).<ref>{{cite book |title=The Nature of Consciousness: Philosophical Debates |editors=N. Block, O. Flanagan, G. Guzeldere |chapter=On a confusion about a function of consciousness |author=[[Ned Block]] |pages=375–415 |year=1998 |isbn=978-0-262-52210-6 |publisher=MIT Press |url=http://cogprints.org/231/1/199712004.html}}</ref>  P-consciousness, according to Block, is simply raw experience:  it is moving, colored forms, sounds, sensations, emotions and feelings with our bodies and responses at the center. These experiences, considered independently of any impact on behavior, are called ''[[qualia]]''.  A-consciousness, on the other hand, is the phenomenon whereby information in our minds is accessible for verbal report, reasoning, and the control of behavior. So, when we [[perception|perceive]], information about what we perceive is access conscious; when we [[introspection|introspect]], information about our thoughts is access conscious; when we [[memory|remember]], information about the past is access conscious, and so on.  Although some philosophers, such as [[Daniel Dennett]], have disputed the validity of this distinction,<ref name="D375">{{cite book |author=[[Daniel Dennett]] |year=2004 |title=[[Consciousness Explained]] |page=375 |publisher=Penguin |isbn=0-7139-9037-6}}</ref> others have broadly accepted it.  [[David Chalmers]] has argued that A-consciousness can in principle be understood in mechanistic terms, but that understanding P-consciousness is much more challenging:  he calls this the ''[[hard problem of consciousness]]''.<ref name=ChalmersHardProblem>{{cite journal |url=http://www.imprint.co.uk/chalmers.html |title=Facing up to the problem of consciousness |author=[[David Chalmers]] |journal=Journal of Consciousness Studies |volume=2 |year=1995 |pages=200–219}}</ref>

Some philosophers believe that Block's two types of consciousness are not the end of the story.  [[William Lycan]], for example, argued in his book ''Consciousness and Experience'' that at least eight clearly distinct types of consciousness can be identified (organism consciousness; control consciousness; consciousness ''of''; state/event consciousness; reportability; introspective consciousness; subjective consciousness; self-consciousness)—and that even this list omits several more obscure forms.<ref>{{cite book |author=[[William Lycan]] |title=Consciousness and Experience |pages=1–4 |year=1996 |publisher=MIT Press |isbn=978-0-262-12197-2}}</ref>

There is also debate over whether or not a-consciousness and p-consciousness always co-exist or if they can exist separately.  Although p-consciousness without a-consciousness is more widely accepted, there have been some hypothetical examples of A without P. Block for instance suggests the case of a “zombie” that is computationally identical to a person but without any subjectivity. However, he remains somewhat skeptical concluding "I don’t know whether there are any actual cases of A-consciousness without P-consciousness, but I hope I have illustrated their conceptual possibility." <ref>{{cite journal | author = Block N | year = 1995 | title = How many concepts of consciousness? | url = | journal = Behavioral and Brain Sciences | volume = 18 | issue = | pages = 272–84 | doi=10.1017/s0140525x00038486}}</ref>

===Forms of consciousness===
While philosophers tend to focus on types of consciousness that occur 'in the mind', in other disciplines such as sociology the emphasis is on the practical meaning of consciousness. In this vein, it is possible to identify four forms of consciousness:<ref>{{Cite book | year=2016 | last1= James | first1= Paul | authorlink1= Paul James (academic) | last2= Steger | first2= Manfred B. | chapter= Globalization and global consciousness: Levels of connectivity | title= Global Culture: Consciousness and Connectivity | editor= Roland Robertson and Didem Buhari | url= https://www.academia.edu/28466384/Globalization_and_Global_Consciousness_Levels_of_Connectivity | publisher= Ashgate | pages=23-24}}</ref> 
<br>1. Sensory experience, "the phenomenal sense that something exists in relation to, or has an impact on, a person". The concept of ‘affect’ attests to this kind of consciousness, as does ‘sense data' "
<br>2. Practical consciousness, or "knowing how to do things, knowing how to ‘go on’. As writers as different as [[Ludwig Wittgenstein | Wittgenstein]] and [[Karl Marx |Marx]] have elaborated, it is "basic to human engagement" 
<br>3. Reflective consciousness, "the modality in which people reflect upon the first two forms. It is the stuff of ordinary philosophy and day-to-day thinking about what has been done and what is to be done"
<br>4. Reflexive consciousness, or "reflecting on the basis of reflection, and interrogating the nature of knowing in the context of the constitutive conditions of being".

===Mind–body problem===
{{main|Mind–body problem}}
[[Image:Descartes mind and body.gif|thumb|200px|right|Illustration of dualism by [[René Descartes]]. Inputs are passed by the sensory organs to the [[pineal gland]] and from there to the immaterial spirit.]]
Mental processes (such as consciousness) and physical processes (such as brain events) seem to be correlated: but what is the basis of this connection and correlation between what seem to be two very different kinds of processes?

The first influential philosopher to discuss this question specifically was [[René Descartes|Descartes]], and the answer he gave is known as [[dualism (philosophy of mind)|Cartesian dualism]].  Descartes proposed that consciousness resides within an immaterial domain he called [[mental substance|res cogitans]] (the realm of thought), in contrast to the domain of material things, which he called [[res extensa]] (the realm of extension).<ref>{{cite book|title=Philosophy of Man: selected readings|last=Dy, Jr.|first=Manuel B.|publisher=Goodwill Trading Co.|year=2001|isbn=971-12-0245-X|page=97}}</ref>  He suggested that the interaction between these two domains occurs inside the brain, perhaps in a small midline structure called the [[pineal gland]].<ref name="Stanford_pineal">{{cite web|title=Descartes and the Pineal Gland|publisher=Stanford University|date=November 5, 2008|url=http://plato.stanford.edu/entries/pineal-gland/|accessdate=2010-08-22}}</ref>

Although it is widely accepted that Descartes explained the problem cogently, few later philosophers have been happy with his solution, and his ideas about the pineal gland have especially been ridiculed.<ref>{{cite web |title=Descartes and the pineal gland |author=Gert-Jan Lokhorst |publisher=Stanford Encyclopedia of Philosophy (Summer 2011 Edition) |editor=Edward N. Zalta |url=http://plato.stanford.edu/archives/sum2011/entries/pineal-gland/}}</ref>  However, no alternative solution has gained general acceptance.  Proposed solutions can be divided broadly into two categories:  [[dualism (philosophy of mind)|dualist]] solutions that maintain Descartes' rigid distinction between the realm of consciousness and the realm of matter but give different answers for how the two realms relate to each other; and [[monism|monist]] solutions that maintain that there is really only one realm of being, of which consciousness and matter are both aspects.  Each of these categories itself contains numerous variants.  The two main types of dualism are [[substance dualism]] (which holds that the mind is formed of a distinct type of substance not governed by the laws of physics) and [[property dualism]] (which holds that the laws of physics are universally valid but cannot be used to explain the mind).  The three main types of monism are [[physicalism]] (which holds that the mind consists of matter organized in a particular way), [[idealism]] (which holds that only thought or experience truly exists, and matter is merely an illusion), and [[neutral monism]] (which holds that both mind and matter are aspects of a distinct essence that is itself identical to neither of them).  There are also, however, a large number of idiosyncratic theories that cannot cleanly be assigned to any of these schools of thought.<ref>{{cite book |author=William Jaworski |title=Philosophy of Mind: A Comprehensive Introduction |publisher=John Wiley and Sons |year=2011 |isbn=978-1-4443-3367-1 |pages=5–11}}</ref>

Since the dawn of Newtonian science with its vision of simple mechanical principles governing the entire universe, some philosophers have been tempted by the idea that consciousness could be explained in purely physical terms. The first influential writer to propose such an idea explicitly was [[Julien Offray de La Mettrie]], in his book ''[[Man a Machine]]'' (''L'homme machine'').  His arguments, however, were very abstract.<ref name=LaMettrie>{{cite book| editor=Ann Thomson |author=[[Julien Offray de La Mettrie]] |title=Machine man and other writings |publisher=Cambridge University Press |year=1996 |isbn=978-0-521-47849-6}}</ref>  The most influential modern physical theories of consciousness are based on [[psychology]] and [[neuroscience]]. Theories proposed by neuroscientists such as [[Gerald Edelman]]<ref>{{cite book|title=Bright Air, Brilliant Fire: On the Matter of the Mind |author=[[Gerald Edelman]] |publisher=Basic Books |year=1993 |isbn=978-0-465-00764-6}}</ref> and [[António Damásio|Antonio Damasio]],<ref name=DamasioFeeling>{{cite book| author=[[Antonio Damasio]] |year=1999 |title=The Feeling of What Happens: Body and Emotion in the Making of Consciousness |location=New York |publisher=Harcourt Press |isbn=978-0-15-601075-7}}</ref> and by philosophers such as [[Daniel Dennett]],<ref>{{cite book |author=[[Daniel Dennett]] |year=1991 |title=Consciousness Explained |location=Boston |publisher=Little & Company |isbn=978-0-316-18066-5}}</ref> seek to explain consciousness in terms of neural events occurring within the brain. Many other neuroscientists, such as [[Christof Koch]],<ref name=KochQuest>{{cite book| author=[[Christof Koch]] |year=2004 |title=The Quest for Consciousness |location=Englewood CO |publisher=Roberts & Company |isbn=978-0-9747077-0-9}}</ref> have explored the neural basis of consciousness without attempting to frame all-encompassing global theories. At the same time, computer scientists working in the field of [[artificial intelligence]] have pursued the goal of creating digital computer programs that can [[Artificial consciousness|simulate or embody consciousness]].<ref>{{cite book |title=Artificial Intelligence: A Modern Approach |authors=Stuart J. Russell, Peter Norvig |chapter=Ch. 26: Philosophical foundations |publisher=Prentice Hall |year=2010 |isbn=978-0-13-604259-4}}</ref>

A few theoretical physicists have argued that classical physics is intrinsically incapable of explaining the holistic aspects of consciousness, but that [[Quantum mechanics|quantum theory]] may provide [[quantum mind|the missing ingredients]]. Several theorists have therefore proposed [[quantum mind]] (QM) theories of consciousness.<ref name="Stanford_qm_cos">{{cite web|title=Quantum Approaches to Consciousness|publisher=Stanford University|date=December 25, 2011|url=http://plato.stanford.edu/entries/qt-consciousness/}}</ref> Notable theories falling into this category include the [[holonomic brain theory]] of [[Karl H. Pribram|Karl Pribram]] and [[David Bohm]], and the [[Orch-OR|Orch-OR theory]] formulated by [[Stuart Hameroff]] and [[Roger Penrose]]. Some of these QM theories offer descriptions of phenomenal consciousness, as well as QM interpretations of access consciousness. None of the quantum mechanical theories has been confirmed by experiment. Recent publications by G. Guerreshi, J. Cia, S. Popescu, and H. Briegel<ref name="Cai2010">{{cite journal |doi=10.1103/PhysRevE.82.021921 |last1=Cai |first1=J. |last2=Popescu |first2=S. |last3=Briegel |first3=H. |title=Persistent dynamic entanglement from classical motion: How bio-molecular machines can generate non-trivial quantum states |journal=Physical Review E |volume=82 |pages=021921 }}</ref> could falsify proposals such as those of Hameroff, which rely on [[quantum entanglement]] in protein. At the present time many scientists and philosophers consider the arguments for an important role of quantum phenomena to be unconvincing.<ref>{{cite book |authors=[[John Searle]] |year=1997 |title=The Mystery of Consciousness |publisher=The New York Review of Books |pages=53–88 |isbn=978-0-940322-06-6}}</ref>

Apart from the general question of the [[Hard problem of consciousness|"hard problem" of consciousness]], roughly speaking, the question of how mental experience arises from a physical basis,<ref name=Gennaro>

For a discussion see {{cite book |title=The Consciousness Paradox: Consciousness, Concepts, and Higher-Order Thoughts |author= Rocco J. Gennaro |url=https://books.google.com/books?id=t-XgKMgzwk4C&pg=PA75&lpg=PA75 |page=75 |chapter=§4.4 The hard problem of consciousness |isbn=0-262-01660-5 |year=2011 |publisher=MIT Press}}

</ref> a more specialized question is how to square the subjective notion that we are in control of our decisions (at least in some small measure) with the customary view of causality that subsequent events are caused by prior events. The topic of [[free will]] is the philosophical and scientific examination of this conundrum.

===Problem of other minds===
Many philosophers consider experience to be the essence of consciousness, and believe that experience can only fully be known from the inside, subjectively.  But if consciousness is subjective and not visible from the outside, why do the vast majority of people believe that other people are conscious, but rocks and trees are not?<ref>{{cite journal |author=Knobe J |year=2008 |title=Can a Robot, an Insect or God Be Aware? |journal=Scientific American: Mind |url=http://www.scientificamerican.com/article.cfm?id=can-a-robot-an-insect-or |doi=10.1038/scientificamericanmind1208-68 |volume=19 |pages=68–71}}</ref>  This is called the [[problem of other minds]].<ref>{{cite book|authors=Alec Hyslop |title=Other Minds |year=1995 |publisher=Springer |isbn=978-0-7923-3245-9 |pages=5–14}}</ref>  It is particularly acute for people who believe in the possibility of [[philosophical zombie]]s, that is, people who think it is possible in principle to have an entity that is physically indistinguishable from a human being and behaves like a human being in every way but nevertheless lacks consciousness.<ref>{{cite web |author=Robert Kirk |title=Zombies |publisher=Stanford Encyclopedia of Philosophy (Summer 2009 Edition) |editor=Edward N. Zalta |url= http://plato.stanford.edu/archives/sum2009/entries/zombies}}</ref> Related issues have also been studied extensively by Greg Littmann of the University of Illinois.<ref name="Ridley Scott pp. 133-144">''The Culture and Philosophy of Ridley Scott'', Greg Littmann, pp. 133-144, Lexington Books (2013).</ref> and Colin Allen a professor at Indiana University regarding the literature and research studying [[artificial intelligence]] in androids.<ref name="Machine Morals 2010">''Moral Machines'', Wendell Wallach and Colin Allen, 288 pages, Oxford University Press, USA (June 3, 2010), ISBN 0199737975.</ref>

The most commonly given answer is that we attribute consciousness to other people because we see that they resemble us in appearance and behavior; we reason that if they look like us and act like us, they must be like us in other ways, including having experiences of the sort that we do.<ref name=HyslopAnalogy/>  There are, however, a variety of problems with that explanation.  For one thing, it seems to violate the [[Occam's razor|principle of parsimony]], by postulating an invisible entity that is not necessary to explain what we observe.<ref name=HyslopAnalogy>{{cite book|authors=Alec Hyslop |chapter=The analogical inference to other minds |title=Other Minds |year=1995 |publisher=Springer |isbn=978-0-7923-3245-9 |pages=41–70}}</ref>  Some philosophers, such as [[Daniel Dennett]] in an essay titled ''The Unimagined Preposterousness of Zombies'', argue that people who give this explanation do not really understand what they are saying.<ref>{{cite journal |authors=[[Daniel Dennett]] |title=The unimagined preposterousness of zombies |journal=Journal of Consciousness Studies |volume=2 |year=1995 |pages=322–325}}</ref>  More broadly, philosophers who do not accept the possibility of zombies generally believe that consciousness is reflected in behavior (including verbal behavior), and that we attribute consciousness on the basis of behavior.  A more straightforward way of saying this is that we attribute experiences to people because of what they can ''do'', including the fact that they can tell us about their experiences.<ref>{{cite journal |authors=[[Stevan Harnad]] |title=Why and how we are not zombies |journal=Journal of Consciousness Studies |year=1995 |volume=1 |pages=164–167}}</ref>

===Animal consciousness===
{{see also|Animal consciousness}}

The topic of animal consciousness is beset by a number of difficulties.  It poses the problem of other minds in an especially severe form, because non-human animals, lacking the ability to express human language, cannot tell us about their experiences.<ref name=Allen>{{cite web |author=Colin Allen |title=Animal consciousness |publisher=Stanford Encyclopedia of Philosophy (Summer 2011 Edition) |editor=Edward N. Zalta |url=http://plato.stanford.edu/archives/sum2011/entries/consciousness-animal/}}</ref>  Also, it is difficult to reason objectively about the question, because a denial that an animal is conscious is often taken to imply that it does not feel, its life has no value, and that harming it is not morally wrong.  Descartes, for example, has sometimes been blamed for mistreatment of animals due to the fact that he believed only humans have a non-physical mind.<ref>{{cite journal |authors=[[Peter Carruthers (philosopher)|Peter Carruthers]] |title=Sympathy and subjectivity |journal=Australasian Journal of Philosophy |year=1999 |volume=77 |pages=465–482 |doi=10.1080/00048409912349231}}</ref>  Most people have a strong intuition that some animals, such as cats and dogs, are conscious, while others, such as insects, are not; but the sources of this intuition are not obvious, and are often based on personal interactions with pets and other animals they have observed.<ref name=Allen/>

Philosophers who consider subjective experience the essence of consciousness also generally believe, as a correlate, that the existence and nature of animal consciousness can never rigorously be known. [[Thomas Nagel]] spelled out this point of view in an influential essay titled ''[[What Is it Like to Be a Bat?]]''.  He said that an organism is conscious "if and only if there is something that it is like to be that organism — something it is like ''for'' the organism"; and he argued that no matter how much we know about an animal's brain and behavior, we can never really put ourselves into the mind of the animal and experience its world in the way it does itself.<ref name=NagelBat>{{cite book| author=[[Thomas Nagel]] |title=Mortal Questions |chapter=Ch. 12 What is it like to be a bat? |publisher=Cambridge University Press |year=1991 |isbn=978-0-521-40676-5}}</ref>  Other thinkers, such as [[Douglas Hofstadter]], dismiss this argument as incoherent.<ref>{{cite book |author=[[Douglas Hofstadter]] |chapter=Reflections on ''What Is It Like to Be a Bat?'' |pages=403–414 |title=[[The Mind's I]] |editors=[[Douglas Hofstadter]] and [[Daniel Dennett]] |publisher=Basic Books |year=1981 |isbn=978-0-7108-0352-8}}</ref>  Several psychologists and ethologists have argued for the existence of animal consciousness by describing a range of behaviors that appear to show animals holding beliefs about things they cannot directly perceive — [[Donald Griffin]]'s 2001 book ''Animal Minds'' reviews a substantial portion of the evidence.<ref name=Griffin2001>{{cite book |title=Animal Minds: Beyond Cognition to Consciousness |author=[[Donald Griffin]] |publisher=University of Chicago Press |year=2001 |isbn=978-0-226-30865-4}}</ref>

On July 7, 2012, eminent scientists from different branches of neuroscience gathered at the [[University of Cambridge]] to celebrate the Francis Crick Memorial Conference, which deals with consciousness in humans and pre-linguistic consciousness in nonhuman animals. After the conference, they signed in the presence of [[Stephen Hawking]], the 'Cambridge Declaration on Consciousness', which summarizes the most important findings of the survey:

"We decided to reach a consensus and make a statement directed to the public that is not scientific. It's obvious to everyone in this room that animals have consciousness, but it is not obvious to the rest of the world. It is not obvious to the rest of the Western world or the Far East. It is not obvious to the society."<ref>{{cite av media|url=https://www.youtube.com/watch?v=RSbom5MsfNM|title=Animal Consciousness Officially Recognized by Leading Panel of Neuroscientists|date=3 September 2012|publisher=|via=YouTube}}</ref>

"Convergent evidence indicates that non-human animals [...], including all mammals and birds, and other creatures, [...] have the necessary neural substrates of consciousness and the capacity to exhibit intentional behaviors."<ref>[http://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf Cambridge Declaration on Consciousness]</ref>

===Artifact consciousness===
{{see also|Artificial consciousness}}

The idea of an [[wikt:artifact|artifact]] made conscious is an ancient theme of mythology, appearing for example in the Greek myth of [[Pygmalion (mythology)|Pygmalion]], who carved a statue that was magically brought to life, and in medieval Jewish stories of the [[Golem]], a magically animated homunculus built of clay.<ref>{{cite book |authors=Moshe Idel |title=Golem: Jewish Magical and Mystical Traditions on the Artificial Anthropoid |year=1990 |publisher=SUNY Press |isbn=978-0-7914-0160-6}} Note: In many stories the Golem was mindless, but some gave it emotions or thoughts.</ref> However, the possibility of actually constructing a conscious machine was probably first discussed by [[Ada Lovelace]], in a set of notes written in 1842 about the [[Analytical Engine]] invented by [[Charles Babbage]], a precursor (never built) to modern electronic computers.  Lovelace was essentially dismissive of the idea that a machine such as the Analytical Engine could think in a humanlike way.  She wrote:

{{quote|It is desirable to guard against the possibility of exaggerated ideas that might arise as to the powers of the Analytical Engine.&nbsp;... The Analytical Engine has no pretensions whatever to ''originate'' anything. It can do whatever we ''know how to order it'' to perform. It can ''follow'' analysis; but it has no power of ''anticipating'' any analytical relations or truths. Its province is to assist us in making ''available'' what we are already acquainted with.<ref>{{cite web |author=[[Ada Lovelace]] |title=Sketch of The Analytical Engine, Note G |url=http://www.fourmilab.ch/babbage/sketch.html}}</ref>}}

One of the most influential contributions to this question was an essay written in 1950 by pioneering computer scientist [[Alan Turing]], titled ''[[Computing Machinery and Intelligence]]''.  Turing disavowed any interest in terminology, saying that even "Can machines think?" is too loaded with spurious connotations to be meaningful; but he proposed to replace all such questions with a specific operational test, which has become known as the [[Turing test]].<ref name="tu">{{cite book |authors=Stuart Shieber |title=The Turing Test : Verbal Behavior as the Hallmark of Intelligence |publisher=MIT Press |year=2004 |isbn=978-0-262-69293-9}}</ref>  To pass the test, a computer must be able to imitate a human well enough to fool interrogators. In his essay Turing discussed a variety of possible objections, and presented a counterargument to each of them.  The Turing test is commonly cited in discussions of [[artificial intelligence]] as a proposed criterion for machine consciousness; it has provoked a great deal of philosophical debate. For example, [[Daniel Dennett]] and [[Douglas Hofstadter]] argue that anything capable of passing the Turing test is necessarily conscious,<ref name=MindsI>{{cite book |authors=[[Daniel Dennett]] and [[Douglas Hofstadter]] |year=1985 |title=The Mind's I |publisher=Basic Books |isbn=978-0-553-34584-1}}</ref> while [[David Chalmers]] argues that a [[philosophical zombie]] could pass the test, yet fail to be conscious.<ref name=Chalmers>{{cite book| authors=[[David Chalmers]] |year=1997 |title=The Conscious Mind: In Search of a Fundamental Theory |publisher=Oxford University Press |isbn=978-0-19-511789-9}}</ref> A third group of scholars have argued that with technological growth once machines begin to display any substantial signs of human-like behavior then the dichotomy (of human consciousness compared to human-like consciousness) becomes passé and issues of machine autonomy begin to prevail even as observed in its nascent form within contemporary industry and technology.<ref name="Ridley Scott pp. 133-144"/><ref name="Machine Morals 2010"/>

In a lively exchange over what has come to be referred to as "the [[Chinese room]] argument", [[John Searle]] sought to refute the claim of proponents of what he calls "strong artificial intelligence (AI)" that a computer program can be conscious, though he does agree with advocates of "weak AI" that computer programs can be formatted to "simulate" conscious states.  His own view is that consciousness has subjective, first-person causal powers by being essentially intentional due simply to the way human brains function biologically; conscious persons can perform computations, but consciousness is not inherently computational the way computer programs are.  To make a Turing machine that speaks Chinese, Searle imagines a room with one monolingual English speaker (Searle himself, in fact), a book that designates a combination of Chinese symbols to be output paired with Chinese symbol input, and boxes filled with Chinese symbols.  In this case, the English speaker is acting as a computer and the rulebook as a program.  Searle argues that with such a machine, he would be able to process the inputs to outputs perfectly without having any understanding of Chinese, nor having any idea what the questions and answers could possibly mean.  If the experiment were done in English, since Searle knows English, he would be able to take questions and give answers without any algorithms for English questions, and he would be effectively aware of what was being said and the purposes it might serve.  Searle would pass the Turing test of answering the questions in both languages, but he is only conscious of what he is doing when he speaks English.  Another way of putting the argument is to say that computer programs can pass the Turing test for processing the syntax of a language, but that the syntax cannot lead to semantic meaning in the way strong AI advocates hoped.<ref name=Searle1990>{{cite journal|author=[[John R. Searle]]|title=Is the brain's mind a computer program |journal=Scientific American |year=1990 |volume=262.1 |pages=26–31 |url=http://www.cs.princeton.edu/courses/archive/spr06/cos116/Is_The_Brains_Mind_A_Computer_Program.pdf |doi=10.1038/scientificamerican0190-26 |pmid=2294583}}</ref><ref name=SearleSEP>{{cite web| title=The Chinese Room Argument| url=http://plato.stanford.edu/entries/chinese-room}}</ref>

In the literature concerning artificial intelligence, Searle's essay has been second only to Turing's in the volume of debate it has generated.<ref name=Searle1980>{{cite journal |author=[[John Searle]]|title=Minds, brains, and programs |journal=Behavioral and Brain Sciences |year=1980 |volume=3 |pages=417–457 |doi=10.1017/S0140525X00005756|display-authors=etal}}</ref>  Searle himself was vague about what extra ingredients it would take to make a machine conscious: all he proposed was that what was needed was "causal powers" of the sort that the brain has and that computers lack. But other thinkers sympathetic to his basic argument have suggested that the necessary (though perhaps still not sufficient) extra conditions may include the ability to pass not just the verbal version of the Turing test, but the [[Robotics|robotic]] version,<ref>{{cite web |author1=Graham Oppy |author2=David Dowe |year=2011 |title=The Turing test |url=http://plato.stanford.edu/archives/spr2011/entries/turing-test |publisher=Stanford Encyclopedia of Philosophy (Spring 2011 Edition)}}</ref> which requires [[Symbol grounding|grounding]] the robot's words in the robot's sensorimotor capacity to [[Categorization|categorize]] and interact with the things in the world that its words are about, Turing-indistinguishably from a real person. Turing-scale robotics is an empirical branch of research on [[embodied cognition]] and [[situated cognition]].<ref>{{cite journal |authors=Margaret Wilson |title=Six views of embodied cognition |journal=Psychonomic Bulletin & Review |volume=9 |year=2002 | pages=625–636 | url=http://philosophy.wisc.edu/shapiro/PHIL951/951articles/wilson.htm|doi=10.3758/BF03196322}}</ref>

==Scientific study==
For many decades, consciousness as a research topic was avoided by the majority of mainstream scientists, because of a general feeling that a phenomenon defined in subjective terms could not properly be studied using objective experimental methods.<ref>{{cite book|authors=Horst Hendriks-Jansen |title=Catching ourselves in the act: situated activity, interactive emergence, evolution, and human thought |year=1996 |publisher=Massachusetts Institute of Technology |page=114 |isbn=0-262-08246-2}}</ref>  In 1975 [[George Mandler]] published an influential psychological study which distinguished between slow, serial, and limited conscious processes and fast, parallel and extensive unconscious ones.<ref>Mandler, G. Consciousness: Respectable, useful, and probably necessary. In R.Solso (Ed.)Information processing and cognition: NJ: LEA.</ref> Starting in the 1980s, an expanding community of neuroscientists and psychologists have associated themselves with a field called ''Consciousness Studies'', giving rise to a stream of experimental work published in books,<ref>Mandler, G.  Consciousness recovered: Psychological functions and origins of thought. Philadelphia: John Benjamins. 2002</ref> journals such as ''[[Consciousness and Cognition]]'', ''[http://www.frontiersin.org/Consciousness_Research Frontiers in Consciousness Research]'', and the ''[[Journal of Consciousness Studies]]'', along with regular conferences organized by groups such as the [[Association for the Scientific Study of Consciousness]].<ref>{{cite book |title=Toward a Science of Consciousness III: The Third Tucson Discussions and Debates |authors=[[Stuart Hameroff]], Alfred Kaszniak, [[David Chalmers]] |chapter=Preface |isbn=978-0-262-58181-3 |publisher=MIT Press |year=1999 |pages=xix–xx}}</ref>

Modern medical and psychological investigations into consciousness are based on psychological experiments (including, for example, the investigation of [[Priming (psychology)|priming]] effects using [[subliminal stimuli]]), and on [[case studies]] of alterations in consciousness produced by trauma, illness, or drugs.  Broadly viewed, scientific approaches are based on two core concepts.  The first identifies the content of consciousness with the experiences that are reported by human subjects; the second makes use of the concept of consciousness that has been developed by neurologists and other medical professionals who deal with patients whose behavior is impaired.  In either case, the ultimate goals are to develop techniques for assessing consciousness objectively in humans as well as other animals, and to understand the neural and psychological mechanisms that underlie it.<ref name=KochQuest/>

===Measurement===
[[File:Necker cube.svg|thumb|right|150px|The [[Necker cube]], an ambiguous image]]
Experimental research on consciousness presents special difficulties, due to the lack of a universally accepted [[operational definition]]. In the majority of experiments that are specifically about consciousness, the subjects are human, and the criterion used is verbal report:  in other words, subjects are asked to describe their experiences, and their descriptions are treated as observations of the contents of consciousness.<ref>{{cite book |authors=[[Bernard Baars]] |title=A Cognitive Theory of Consciousness |year=1993 |publisher=Cambridge University Press |isbn=978-0-521-42743-2| pages=15–18}}</ref>  For example, subjects who stare continuously at a [[Necker cube]] usually report that they experience it "flipping" between two 3D configurations, even though the stimulus itself remains the same.<ref>{{cite book |title=Perception: Theory, Development, and Organization |authors=Paul Rooks and Jane Wilson |year=2000 |publisher=Psychology Press |isbn=978-0-415-19094-7 |pages=25–26}}</ref>  The objective is to understand the relationship between the conscious awareness of stimuli (as indicated by verbal report) and the effects the stimuli have on brain activity and behavior. In several paradigms, such as the technique of [[response priming]], the behavior of subjects is clearly influenced by stimuli for which they report no awareness, and suitable experimental manipulations can lead to ''increasing'' priming effects despite ''decreasing'' prime identification (double dissociation).<ref name=Schmidt>{{cite journal |authors=Thomas Schmidt and Dirk Vorberg |title=Criteria for unconscious cognition: Three types of dissociation |journal=Perception and Psychophysics |volume=68 |year=2006 |pages=489–504 |doi=10.3758/bf03193692 |pmid=16900839 |issue=3}}</ref>

Verbal report is widely considered to be the most reliable indicator of consciousness, but it raises a number of issues.<ref name=Destrebecqz/>  For one thing, if verbal reports are treated as observations, akin to observations in other branches of science, then the possibility arises that they may contain errors—but it is difficult to make sense of the idea that subjects could be wrong about their own experiences, and even more difficult to see how such an error could be detected.<ref>{{cite book |chapter=Quining qualia |authors=[[Daniel Dennett]] |title=Consciousness in Modern Science |editors=A. Marcel and E. Bisiach |publisher=Oxford University Press |year=1992 |url=http://cogprints.org/254/ |accessdate=2011-10-31 |isbn=978-0-19-852237-9}}</ref>  [[Daniel Dennett]] has argued for an approach he calls [[heterophenomenology]], which means treating verbal reports as stories that may or may not be true, but his ideas about how to do this have not been widely adopted.<ref>{{cite journal |author=[[Daniel Dennett]] |year=2003 |title=Who's on first? Heterophenomenology explained |journal=Journal of Consciousness Studies |volume=10 |pages=19–30}}</ref>  Another issue with verbal report as a criterion is that it restricts the field of study to humans who have language:  this approach cannot be used to study consciousness in other species, pre-linguistic children, or people with types of brain damage that impair language.  As a third issue, philosophers who dispute the validity of the [[Turing test]] may feel that it is possible, at least in principle, for verbal report to be dissociated from consciousness entirely:  a [[philosophical zombie]] may give detailed verbal reports of awareness in the absence of any genuine awareness.<ref>{{cite book |authors=[[David Chalmers]] |title=The Conscious Mind |year=1996 |chapter=Ch. 3: Can consciousness be reductively explained? |publisher=Oxford University Press |isbn=978-0-19-511789-9}}</ref>

Although verbal report is in practice the "gold standard" for ascribing consciousness, it is not the only possible criterion.<ref name=Destrebecqz>{{cite book |title=The Boundaries of Consciousness: Neurobiology and Neuropathology |chapter=Methods for studying unconscious learning |authors=Arnaud Destrebecqz and Philippe Peigneux |editor=Steven Laureys |year=2006 |publisher=Elsevier |isbn=978-0-444-52876-6 |pages=69–80}}</ref>  In medicine, consciousness is assessed as a combination of verbal behavior, arousal, brain activity and purposeful movement.  The last three of these can be used as indicators of consciousness when verbal behavior is absent.<ref name=Giacino/>  The scientific literature regarding the neural bases of arousal and purposeful movement is very extensive.  Their reliability as indicators of consciousness is disputed, however, due to numerous studies showing that alert human subjects can be induced to behave purposefully in a variety of ways in spite of reporting a complete lack of awareness.<ref name=Schmidt/>  Studies of the [[neuroscience of free will]] have also shown that the experiences that people report when they behave purposefully sometimes do not correspond to their actual behaviors or to the patterns of electrical activity recorded from their brains.<ref>{{cite journal |title=Human volition: towards a neuroscience of will |authors=Patrick Haggard |journal=Nature Reviews Neuroscience |year=2008 |volume=9 |pages=934–946 |pmid=19020512 |doi=10.1038/nrn2497 |issue=12}}</ref>

Another approach applies specifically to the study of [[self-awareness]], that is, the ability to distinguish oneself from others.  In the 1970s [[Gordon G. Gallup|Gordon Gallup]] developed an operational test for self-awareness, known as the [[mirror test]].  The test examines whether animals are able to differentiate between seeing themselves in a mirror versus seeing other animals. The classic example involves placing a spot of coloring on the skin or fur near the individual's forehead and seeing if they attempt to remove it or at least touch the spot, thus indicating that they recognize that the individual they are seeing in the mirror is themselves.<ref>{{cite journal |author=[[Gordon G. Gallup|Gordon Gallup]] |title=Chimpanzees: Self recognition |journal=Science |volume=167 |pages=86–87 |year=1970 |doi=10.1126/science.167.3914.86 |pmid=4982211 |issue=3914}}</ref>  Humans (older than 18 months) and other [[Hominidae|great apes]], [[bottlenose dolphin]]s, killer whales, pigeons, European magpies and elephants have all been observed to pass this test.<ref>{{cite journal |title=Animal consciousness: a synthetic approach |authors=David Edelman and Anil Seth |journal=Trends in Neurosciences |year=2009 |volume=32 |pages=476–484 |pmid=19716185 |doi=10.1016/j.tins.2009.05.008 |issue=9}}</ref>

===Neural correlates===
[[File:Neural Correlates Of Consciousness.jpg|thumb|right|550px|{{center|Schema of the neural processes underlying consciousness, from [[Christof Koch]]}}]]

A major part of the scientific literature on consciousness consists of studies that examine the relationship between the experiences reported by subjects and the activity that simultaneously takes place in their brains—that is, studies of the [[neural correlates of consciousness]].  The hope is to find that activity in a particular part of the brain, or a particular pattern of global brain activity, which will be strongly predictive of conscious awareness.  Several brain imaging techniques, such as [[EEG]] and [[fMRI]], have been used for physical measures of brain activity in these studies.<ref>{{cite book| authors=[[Christof Koch]] |year=2004 |title=The Quest for Consciousness |location=Englewood CO |publisher=Roberts & Company |isbn=978-0-9747077-0-9 |pages=16–19}}</ref>

Another idea that has drawn attention for several decades is that consciousness is associated with high-frequency (gamma band) [[neural oscillations|oscillations in brain activity]].  This idea arose from proposals in the 1980s, by Christof von der Malsburg and Wolf Singer, that gamma oscillations could solve the so-called [[binding problem]], by linking information represented in different parts of the brain into a unified experience.<ref>{{cite web |title=Binding by synchrony |author=Wolf Singer |publisher=[[Scholarpedia]] |url=http://www.scholarpedia.org/article/Binding_by_synchrony |accessdate=2011-10-26}}</ref>  [[Rodolfo Llinás]], for example, proposed that consciousness results from [[recurrent thalamo-cortical resonance]] where the specific thalamocortical systems (content) and the non-specific (centromedial thalamus) thalamocortical systems (context) interact in the [[gamma wave|gamma]] band frequency via synchronous oscillations.<ref>{{cite book |author=[[Rodolfo Llinás]] |year=2002 |title=I of the Vortex. From Neurons to Self |publisher=MIT Press |isbn=978-0-262-62163-2}}</ref>

A number of studies have shown that activity in primary sensory areas of the brain is not sufficient to produce consciousness:  it is possible for subjects to report a lack of awareness even when areas such as the [[primary visual cortex]] show clear electrical responses to a stimulus.<ref>Koch, ''The Quest for Consciousness'', pp. 105–116</ref>  Higher brain areas are seen as more promising, especially the [[prefrontal cortex]], which is involved in a range of higher cognitive functions collectively known as [[executive functions]].  There is substantial evidence that a "top-down" flow of neural activity (i.e., activity propagating from the frontal cortex to sensory areas) is more predictive of conscious awareness than a "bottom-up" flow of activity.<ref>{{cite journal |title=A framework for consciousness |authors=[[Francis Crick]] and [[Christof Koch]] |year=2003 |journal=Nature Neuroscience |volume=6 |pages=119–126 |pmid=12555104 |url=http://papers.klab.caltech.edu/29/1/438.pdf |format=PDF |doi=10.1038/nn0203-119 |issue=2}}</ref>  The prefrontal cortex is not the only candidate area, however:  studies by Nikos Logothetis and his colleagues have shown, for example, that visually responsive neurons in parts of the [[temporal lobe]] reflect the visual perception in the situation when conflicting visual images are presented to different eyes (i.e., bistable percepts during binocular rivalry).<ref>Koch, ''The Quest for Consciousness'', pp. 269–286</ref>

Modulation of neural responses may correlate with phenomenal experiences. In contrast to the raw electrical responses that do not correlate with consciousness, the modulation of these responses by other stimuli correlates surprisingly well with an important aspect of consciousness: namely with the phenomenal experience of stimulus intensity (brightness, contrast). In the research group of Danko Nikolić it has been shown that some of the changes in the subjectively perceived brightness correlated with the modulation of firing rates while others correlated with the modulation of neural synchrony.<ref>{{cite journal |author1=Biederlack J. |author2=Castelo-Branco M. |author3=Neuenschwander S. |author4=Wheeler D.W. |author5=Singer W. |author6=Nikolić D. | year = 2006 | title = Brightness induction: Rate enhancement and neuronal synchronization as complementary codes | url = | journal = Neuron | volume = 52 | issue = | pages = 1073–1083 | doi=10.1016/j.neuron.2006.11.012}}</ref> An fMRI investigation suggested that these findings were strictly limited to the primary visual areas.<ref>{{cite journal |author1=Williams Adrian L. |author2=Singh Krishna D. |author3=Smith Andrew T. | year = 2003 | title = Surround modulation measured with functional MRI in the human visual cortex | url = | journal = Journal of Neurophysiology | volume = 89 | issue = 1| pages = 525–533 | doi=10.1152/jn.00048.2002}}</ref> This indicates that, in the primary visual areas, changes in firing rates and synchrony can be considered as neural correlates of qualia—at least for some type of qualia.

In 2011, [[Michael Graziano|Graziano]] and Kastner<ref name=Graziano&Kastner2011>{{cite journal |author1=Graziano, M.S.A.  |author2=Kastner, S | year=2011 | title=Human consciousness and its relationship to social neuroscience: A novel hypothesis | journal=Cog. Neurosci | volume=2 | pages=98–113 | doi=10.1080/17588928.2011.565121 | pmid=22121395 | pmc=3223025}}</ref> proposed the "attention schema" theory of awareness. In that theory, specific cortical areas, notably in the superior temporal sulcus and the temporo-parietal junction, are used to build the construct of awareness and attribute it to other people. The same cortical machinery is also used to attribute awareness to oneself. Damage to these cortical regions can lead to deficits in consciousness such as [[hemispatial neglect]]. In the [[attention]] schema theory, the value of explaining the feature of awareness and attributing it to a person is to gain a useful predictive model of that person's attentional processing. [[Attention]] is a style of [[information processing]] in which a brain focuses its resources on a limited set of interrelated signals. Awareness, in this theory, is a useful, simplified schema that represents attentional states. To be aware of X is explained by constructing a model of one's attentional focus on X.

In the 2013, the ''perturbational complexity index'' (PCI) was proposed, a measure of the algorithmic complexity of the electrophysiological response of the cortex to [[transcranial magnetic stimulation]]. This measure was shown to be higher in individuals that are awake, in REM sleep or in a locked-in state than in those who are in deep sleep or in a vegetative state,<ref>{{cite journal|author1=Adenauer G. Casali|author2=Olivia Gosseries|author3=Mario Rosanova|author4=Mélanie Boly|author5=Simone Sarasso|author6=Karina R. Casali|author7=Silvia Casarotto|author8=Marie-Aurélie Bruno|author9=Steven Laureys|author10=[[Giulio Tononi]]|author11=Marcello Massimini|title=A Ttheoretically based index of consciousness independent of sensory processing and behavior|journal=Science Translational Medicine|date=14 August 2013|volume=5|number=198|pages=198ra105|doi=10.1126/scitranslmed.3006294}}</ref> making it potentially useful as a quantitative assessment of consciousness states.

Assuming that not only humans but even some non-mammalian species are conscious, a number of evolutionary approaches to the problem of neural correlates of consciousness open up. For example, assuming that birds are conscious — a common assumption among neuroscientists and ethologists due to the extensive cognitive repertoire of birds — there are comparative neuroanatomical ways to validate some of the principal, currently competing, mammalian consciousness–brain theories. The rationale for such a comparative study is that the avian brain deviates structurally from the mammalian brain. So how similar are they? What homologues can be identified? The general conclusion from the study by Butler, et al.,<ref name=Butler2005>{{cite journal |author1=Ann B. Butler |author2=Paul R. Manger |author3=B.I.B Lindahl |author4=Peter Århem | year=2005 | title=Evolution of the neural basis of consciousness: a bird-mammal comparison | journal=BioEssays | volume=27 | pages=923–936 | doi=10.1002/bies.20280}}</ref> is that some of the major theories for the mammalian brain <ref name=Crick1995>{{cite journal | author=[[Francis Crick]] and [[Christof Koch]] | year=1995 | title=Are we aware of neural activity in primary visual cortex? | journal=Nature | volume=375 | pages=121–123 | doi=10.1038/375121a0 | issue=6527}}</ref><ref name=Edelman2000>{{cite book| author=[[Gerald Edelman|Gerald M. Edelman]] and [[Giulio Tononi]] |year=2000|title=A Universe of Consciousness: How Matter Becomes Imagination|publisher=Basic Books |isbn=0-465-01376-7}}</ref><ref name=Cotterill2001>{{cite journal |author=Rodney M.J. Cotterill |title=Cooperation of the basal ganglia, cerebellum, sensory cerebrum and hippocampus: possible implications for cognition, consciousness, intelligence and creativity|journal=Progress in Neurobiology|year=2001 | volume=64 |pages=1–33 |doi=10.1016/s0301-0082(00)00058-7}}</ref> also appear to be valid for the avian brain. The structures assumed to be critical for consciousness in mammalian brains have homologous counterparts in avian brains. Thus the main portions of the theories of Crick and Koch,<ref name="Crick1995"/> Edelman and Tononi,<ref name="Edelman2000"/> and Cotterill <ref name="Cotterill2001"/> seem  to be compatible with the assumption that birds are conscious. Edelman also differentiates between what he calls primary consciousness (which is a trait shared by humans and non-human animals) and higher-order consciousness as it appears in humans alone along with human language capacity.<ref name="Edelman2000"/> Certain aspects of the three theories, however, seem less easy to apply to the hypothesis of avian consciousness. For instance, the suggestion by Crick and Koch that layer 5 neurons of the mammalian brain have a special role, seems difficult to apply to the avian brain, since the avian homologues have a different morphology. Likewise, the theory of Eccles<ref>{{cite journal| year=1982 |author=[[John Eccles (neurophysiologist)|J.C. Eccles]] | title=Animal consciousness and human self-consciousness|journal=Experientia|volume=38|issue=12|pages=1384–1391|doi=10.1007/bf01955747}}</ref><ref>{{cite journal| year=1990 |author=[[John Eccles (neurophysiologist)|John Eccles]] | title=A unitary hypothesis of mind-brain interaction in the cerebral cortex|journal=Proceedings of the Royal Society of London, B|volume=240|pages=433–451|doi=10.1098/rspb.1990.0047}}</ref> seems incompatible, since a structural homologue/analogue to the dendron has not been found in avian brains. The assumption of an avian consciousness also brings the reptilian brain into focus. The reason is the structural continuity between avian and reptilian brains, meaning that the phylogenetic origin of consciousness may be earlier than suggested by many leading neuroscientists.

Joaquin Fuster of UCLA has advocated the position of the importance of the prefrontal cortex in humans, along with the areas of Wernicke and Broca, as being of particular importance to the development of human language capacities neuro-anatomically necessary for the emergence of higher-order consciousness in humans.<ref>Joaquin Fuster, ''The Prefrontal Cortex'', Second Edition.</ref>

===Biological function and evolution===
Opinions are divided as to where in biological [[evolution]] consciousness emerged and about whether or not consciousness has any survival value. It has been argued that consciousness emerged (i) exclusively with the first humans, (ii) exclusively with the first mammals, (iii) independently in mammals and birds, or (iv) with the first reptiles.<ref>{{cite book |authors=Peter Århem, B. I. B. Lindahl, Paul R. Manger, and Ann B. Butler |year=2008 |editors=Hans Liljenström, Peter Århem |chapter=On the origin of consciousness — some amniote scenarios|title= Consciousness Transitions: Phylogenetic, Ontogenetic, and Physiological Aspects|publisher=Elsevier. |url=https://books.google.com/books?id=OQGJz1DVQNMC&pg=PA77 |isbn=978-0-444-52977-0}}</ref> Other authors date the origins of consciousness to the first animals with nervous systems or early vertebrates in the Cambrian over 500 million years ago.<ref>{{cite journal |last=Feinberg |first=TE |last2=Mallatt |first2=J |date=October 2013 |title=The evolutionary and genetic origins of consciousness in the Cambrian Period over 500 million years ago. |journal=Frontiers in psychology |doi=10.3389/fpsyg.2013.00667 |pmid=24109460 |volume=4 |pages=667 |pmc=3790330}}</ref> [[Donald Griffin]] suggests in his book ''Animal Minds'' a gradual evolution of consciousness.<ref name="Griffin2001"/> Each of these scenarios raises the question of the possible survival value of consciousness.

[[Thomas Henry Huxley]] defends in an essay titled ''On the Hypothesis that Animals are [[Automaton|Automata]], and its History'' an [[epiphenomenalism|epiphenomenalist]] theory of consciousness according to which consciousness is a causally inert effect of neural activity — “as the steam-whistle which accompanies the work of a locomotive engine is without influence upon its machinery”.<ref>{{cite journal |authors=[[T. H. Huxley]] |title=On the hypothesis that animals are automata, and its history |journal=The Fortnightly Review |volume=16 |pages=555–580|year=1874}}</ref> To this [[William James]] objects in his essay ''Are We Automata?'' by stating an evolutionary argument for mind-brain interaction implying that if the preservation and development of consciousness in the biological evolution is a result of [[natural selection]], it is plausible that consciousness has not only been influenced by neural processes, but has had a survival value itself; and it could only have had this if it had been efficacious.<ref>{{cite journal |authors=[[William James|W. James]] |title=Are we automata?|journal=Mind |volume=4 |pages=1–22|year=1879 |doi=10.1093/mind/os-4.13.1}}</ref><ref>{{cite journal |authors=B. I. B. Lindahl |title=Consciousness and biological evolution|journal=Journal of Theoretical Biology|volume=187 |pages=613–629|year=1997 |doi=10.1006/jtbi.1996.0394}}</ref> [[Karl Popper]] develops in the book ''The Self and Its Brain'' a similar evolutionary argument.<ref name=Popper1977>{{cite book |title=The Self and Its Brain |author=[[Karl Popper|Karl R. Popper]], [[John Eccles (neurophysiologist)|John C. Eccles]]|publisher=Springer International |year=1977|isbn=0-387-08307-3}}</ref>

Regarding the primary function of conscious processing, a recurring idea in recent theories is that phenomenal states somehow integrate neural activities and information-processing that would otherwise be independent.<ref>{{cite journal |authors=[[Bernard Baars]] |title=The conscious access hypothesis: Origins and recent evidence |journal=Trends in Cognitive Sciences |volume=6 |pages=47–52 |pmid=11849615 |doi=10.1016/S1364-6613(00)01819-2 |issue=1 |date=January 2002}}</ref> This has been called the ''integration consensus''. Another example has been proposed by [[Gerald Edelman]] called dynamic core hypothesis which puts emphasis on [[reentry (neural circuitry)|reentrant]] connections that reciprocally link areas of the brain in a massively parallel manner.<ref>{{cite journal|last=Seth|first=Anil|author2=Eugene Izhikevich |author3=George Reeke |author4=Gerald Edelman |title=Theories and measures of consciousness: An extended framework|journal=Proceedings of the National Academy of Sciences|year=2006|volume=103|issue=28|doi=10.1073/pnas.0604347103 |pages=10799–10804}}</ref> Edelman also stresses the importance of the evolutionary emergence of higher-order consciousness in humans from the historically older trait of primary consciousness which humans share with non-human animals (see ''[[#Neural correlates|Neural correlates]]'' section above). These theories of integrative function present solutions to two classic problems associated with consciousness: differentiation and unity. They show how our conscious experience can discriminate between a virtually unlimited number of different possible scenes and details (differentiation) because it integrates those details from our sensory systems, while the integrative nature of consciousness in this view easily explains how our experience can seem unified as one whole despite all of these individual parts. However, it remains unspecified which kinds of information are integrated in a conscious manner and which kinds can be integrated without consciousness. Nor is it explained what specific causal role conscious integration plays, nor why the same functionality cannot be achieved without consciousness. Obviously not all kinds of information are capable of being disseminated consciously (e.g., neural activity related to vegetative functions, reflexes, unconscious motor programs, low-level perceptual analyses, etc.) and many kinds of information can be disseminated and combined with other kinds without consciousness, as in intersensory interactions such as the ventriloquism effect.<ref name="ReferenceA">{{cite journal |authors=Ezequiel Morsella |year=2005 |title=The function of phenomenal states: Supramodular Interaction Theory |journal=Psychological Review |volume=112 |pages=1000–1021 |pmid=16262477 |issue=4 |doi=10.1037/0033-295X.112.4.1000}}</ref> Hence it remains unclear why any of it is conscious. For a review of the differences between conscious and unconscious integrations, see the article of E. Morsella.<ref name="ReferenceA"/>

As noted earlier, even among writers who consider consciousness to be a well-defined thing, there is [[Animal consciousness|widespread dispute]] about which animals other than humans can be said to possess it.<ref name = "ingvww">{{cite book |author=S. Budiansky |title=If a Lion Could Talk: Animal Intelligence and the Evolution of Consciousness |year=1998 |publisher=The Free Press |isbn=978-0-684-83710-9}}</ref> Edelman has described this distinction as that of humans possessing higher-order consciousness while sharing the trait of primary consciousness with non-human animals (see previous paragraph). Thus, any examination of the evolution of consciousness is faced with great difficulties.  Nevertheless, some writers have argued that consciousness can be viewed from the standpoint of  [[evolutionary biology]] as an [[adaptation]] in the sense of a [[Phenotypic trait|trait]] that increases [[Fitness (biology)|fitness]].<ref>{{cite journal |authors=S. Nichols, T. Grantham |title=Adaptive Complexity and Phenomenal Consciousness |year=2000 |journal=Philosophy of Science |volume=67 |pages=648–670 |doi=10.1086/392859}}</ref>  In his article "Evolution of consciousness", John Eccles argued that special anatomical and physical properties of the mammalian [[cerebral cortex]] gave rise to consciousness ("[a] psychon ... linked to [a] dendron through quantum physics").<ref>{{cite journal |author=[[John Eccles (neurophysiologist)|John Eccles]] |title=Evolution of consciousness |journal=Proc. Natl. Acad. Sci. U.S.A. |volume=89 |pages=7320–7324 |year=1992 |pmid=1502142 |pmc=49701 |doi=10.1073/pnas.89.16.7320}}</ref>  Bernard Baars proposed that once in place, this "recursive" circuitry may have provided a basis for the subsequent development of many of the functions that consciousness facilitates in higher organisms.<ref name=Baars>{{cite book |author=[[Bernard Baars]] |title=A Cognitive Theory of Consciousness |year=1993 |publisher=Cambridge University Press |isbn=978-0-521-42743-2}}</ref> [[Peter Carruthers (philosopher)|Peter Carruthers]] has put forth one such potential adaptive advantage gained by conscious creatures by suggesting that consciousness allows an individual to make distinctions between appearance and reality.<ref>{{cite book|last=Carruthers|first=Peter|title=Phenomenal Consciousness: A Naturalistic Theory|year=2004|publisher=Cambridge University Press|location=Cambridge, UK}}</ref> This ability would enable a creature to recognize the likelihood that their perceptions are deceiving them (e.g. that water in the distance may be a mirage) and behave accordingly, and it could also facilitate the manipulation of others by recognizing how things appear to them for both cooperative and devious ends.

Other philosophers, however, have suggested that consciousness would not be necessary for any functional advantage in evolutionary processes.<ref>{{cite journal| authors=[[Owen Flanagan]] and T. W. Polger |year=1995 |title=Zombies and the function of consciousness |journal=Journal of Consciousness Studies |volume=2 |pages=313–321}}</ref><ref>{{cite journal|last=Rosenthal|first=David|title=Consciousness and its function|journal=Neuropsychologia|year=2008|volume=46|pages=829–840|doi=10.1016/j.neuropsychologia.2007.11.012}}</ref> No one has given a causal explanation, they argue, of why it would not be possible for a functionally equivalent non-conscious organism (i.e., a [[philosophical zombie]]) to achieve the very same survival advantages as a conscious organism. If evolutionary processes are blind to the difference between function ''F'' being performed by conscious organism ''O'' and non-conscious organism ''O*'', it is unclear what adaptive advantage consciousness could provide.<ref>{{cite book| author=[[Stevan Harnad]] |year=2002 |chapter= Turing indistinguishability and the Blind Watchmaker |editor=J. H. Fetzer |title=Consciousness Evolving |publisher=John Benjamins |url=http://cogprints.org/1615 |accessdate=2011-10-26}}</ref> As a result, an exaptive explanation of consciousness has gained favor with some theorists that posit consciousness did not evolve as an adaptation but was an [[exaptation]] arising as a consequence of other developments such as increases in brain size or cortical rearrangement.<ref>{{cite journal | pmc = 3790330 | pmid=24109460 | doi=10.3389/fpsyg.2013.00667 | volume=4 | title=The evolutionary and genetic origins of consciousness in the Cambrian Period over 500 million years ago. | year=2013 | journal=Front Psychol | pages=667}}</ref> Consciousness in this sense has been compared to the blind spot in the retina where it is not an adaption of the retina, but instead just a by-product of the way the retinal axons were wired.<ref>{{cite journal |author1=Zack ROBINSON |author2=Corey J. MALEY |author3=Gualtiero PICCININI | year = 2015 | title = Is Consciousness a Spandrel?. | url = | journal = Journal of the American Philosophical Association | volume = 1 | issue = | pages = 365–383 | doi = 10.1017/apa.2014.10 }}</ref>  Several scholars including Pinker, Chomsky, Edelman, and Luria have indicated the importance of the emergence of human language as an important regulative mechanism of learning and memory in the context of the development of higher-order consciousness (see ''[[#Neural correlates|Neural correlates]]'' section above).

===States of consciousness===
[[File:Abbot of Watkungtaphao in Phu Soidao Waterfall.jpg|thumb|right|150px|A Buddhist monk meditating]]
There are some brain states in which consciousness seems to be absent, including dreamless sleep, coma, and death.  There are also a variety of circumstances that can change the relationship between the mind and the world in less drastic ways, producing what are known as [[altered state of consciousness|altered states of consciousness]].  Some altered states occur naturally; others can be produced by drugs or brain damage.<ref name=Vaitl>{{cite journal |authors=Dieter Vaitl |title=Psychobiology of altered states of consciousness |year=2005 |journal=Psychological Bulletin |volume=131 |pages=98–127 |doi=10.1037/0033-2909.131.1.98 |pmid=15631555 |issue=1|display-authors=etal}}</ref> Altered states can be accompanied by changes in thinking, disturbances in the sense of time, feelings of loss of control, changes in emotional expression, alternations in body image and changes in meaning or significance.<ref>{{cite book|last1=Schacter|first1=Daniel|last2=Gilbert|first2=Daniel|last3=Wegner|first3=Daniel|title=Psychology 2nd Ed.|year=2011|publisher=Worth Publishers|location=41 Madison Avenue, New York, NY 10010|page=190|isbn=1-4292-3719-8}}</ref>

The two most widely accepted altered states are [[sleep]] and [[dream]]ing.  Although dream sleep and non-dream sleep appear very similar to an outside observer, each is associated with a distinct pattern of brain activity, metabolic activity, and eye movement;  each is also associated with a distinct pattern of experience and cognition.  During ordinary non-dream sleep, people who are awakened report only vague and sketchy thoughts, and their experiences do not cohere into a continuous narrative.  During dream sleep, in contrast, people who are awakened report rich and detailed experiences in which events form a continuous progression, which may however be interrupted by bizarre or fantastic intrusions.<ref>{{cite journal |authors=Anton Coenen |title=Subconscious Stimulus Recognition and Processing During Sleep | url = http://journalpsyche.org/archive/volume-16-no-2-2010/ |year=2010 |journal=Psyche |volume=16-2}}</ref>  Thought processes during the dream state frequently show a high level of irrationality.  Both dream and non-dream states are associated with severe disruption of memory:  it usually disappears in seconds during the non-dream state, and in minutes after awakening from a dream unless actively refreshed.<ref>{{cite book |authors=[[J. Allan Hobson]], Edward F. Pace-Schott, and [[Robert Stickgold]] |chapter=Dreaming and the brain: Toward a cognitive neuroscience of conscious states |title=Sleep and Dreaming: Scientific Advances and Reconsiderations |editors=Edward F. Pace-Schott, Mark Solms, Mark Blagrove, Stevan Harnad |year=2003 |publisher=Cambridge University Press |isbn=978-0-521-00869-3}}</ref>

Research conducted on the effects of partial epileptic seizures on consciousness found that patients who suffer from partial epileptic seizures experience altered states of consciousness.<ref>] Johanson, M., Valli, K., Revonsuo, A., & Wedlund, J., 2008. Content analysis of subjective experiences in partial epileptic seizures. ''Epilepsy and Behavior'', 12, pp 170-182</ref><ref>{{cite journal |author1=Johanson M. |author2=Valli K. |author3=Revonsuo A. | year = 2008 | title = Alterations in the contents of consciousness in partial epileptic seizures | url = | journal = Epilepsy and Behavior | volume = 13 | issue = | pages = 366–371 | doi=10.1016/j.yebeh.2008.04.014|display-authors=etal}}</ref> In partial epileptic seizures, consciousness is impaired or lost while some aspects of consciousness, often automated behaviors, remain intact. Studies found that when measuring the qualitative features during partial epileptic seizures, patients exhibited an increase in arousal and became absorbed in the experience of the seizure, followed by difficulty in focusing and shifting attention.

A variety of [[psychoactive drug]]s and [[Ethanol|alcohol]] have notable effects on consciousness.<ref name="DSMIV">{{Cite book| title = Diagnostic and statistical manual of mental disorders: DSM-IV | url = https://books.google.com/?id=W-BGAAAAMAAJ | date = 31 July 1994 | publisher = American Psychiatric Association | location = Washington, DC | isbn = 978-0-89042-025-6}}</ref> These range from a simple dulling of awareness produced by [[sedative]]s, to increases in the intensity of sensory qualities produced by [[stimulant]]s, [[cannabis (drug)|cannabis]], empathogens–entactogens such as MDMA ("Ecstasy"), or most notably by the class of drugs known as [[psychedelic drug|psychedelics]].<ref name=Vaitl/> [[Lysergic acid diethylamide|LSD]], [[mescaline]], [[psilocybin]], [[Dimethyltryptamine]], and others in this group can produce major distortions of perception, including hallucinations; some users even describe their drug-induced experiences as mystical or spiritual in quality. The brain mechanisms underlying these effects are not as well understood as those induced by use of [[Ethanol|alcohol]],<ref name="DSMIV"/> but there is substantial evidence that alterations in the brain system that uses the chemical neurotransmitter [[serotonin]] play an essential role.<ref>{{cite web |author=Michael Lyvers |title=The neurochemistry of psychedelic experiences |year=2003 |publisher=ePublications@bond |url=http://epublications.bond.edu.au/hss_pubs/10 |format=PDF}}</ref>

There has been some research into physiological changes in yogis and people who practise various techniques of meditation.  Some research with brain waves during meditation has reported differences between those corresponding to ordinary relaxation and those corresponding to meditation.  It has been disputed, however, whether there is enough evidence to count these as physiologically distinct states of consciousness.<ref name=MurphyMeditation>{{cite book |authors=M. Murphy, S. Donovan, and E. Taylor |year=1997 |title=The Physical and Psychological Effects of Meditation: A Review of Contemporary Research With a Comprehensive Bibliography, 1931–1996 |publisher=Institute of Noetic Sciences}}</ref>

The most extensive study of the characteristics of altered states of consciousness was made by psychologist [[Charles Tart]] in the 1960s and 1970s.  Tart analyzed a state of consciousness as made up of a number of component processes, including exteroception (sensing the external world); interoception (sensing the body); input-processing (seeing meaning); emotions; memory; time sense; sense of identity; evaluation and cognitive processing; motor output; and interaction with the environment.<ref>{{cite book |author=[[Charles Tart]] |title=States of Consciousness |chapter=Ch. 2: The components of consciousness |year=2001 |publisher=IUniverse.com |isbn=978-0-595-15196-7 |url=http://www.psychedelic-library.org/soc2.htm |accessdate=2011-10-05}}</ref>  Each of these, in his view, could be altered in multiple ways by drugs or other manipulations.  The components that Tart identified have not, however, been validated by empirical studies.  Research in this area has not yet reached firm conclusions, but a recent questionnaire-based study identified eleven significant factors contributing to drug-induced states of consciousness:  experience of unity; spiritual experience; blissful state; insightfulness; disembodiment; impaired control and cognition; anxiety; complex imagery; elementary imagery; audio-visual [[synesthesia]]; and changed meaning of percepts.<ref>{{cite journal |title=Psychometric evaluation of the altered states of consciousness rating scale (OAV)| authors=E. Studerus, A. Gamma, and F. X. Vollenweider |journal=[[PLoS ONE]] |year=2010 |volume=8 |pmid=20824211 |pmc=2930851|doi=10.1371/journal.pone.0012412 |pages=e12412}}</ref>

===Phenomenology===
Phenomenology is a method of inquiry that attempts to examine the structure of consciousness in its own right, putting aside problems regarding the relationship of consciousness to the physical world. This approach was first proposed by the philosopher [[Edmund Husserl]], and later elaborated by other philosophers and scientists.<ref>{{cite book |author=Robert Sokolowski |title=Introduction to Phenomenology |year=2000 |publisher=Cambridge University Press |pages=211–227 |isbn=978-0-521-66792-0}}</ref> Husserl's original concept gave rise to two distinct lines of inquiry, in philosophy and psychology. [[phenomenology (philosophy)|In philosophy]], phenomenology has largely been devoted to fundamental metaphysical questions, such as the nature of [[intentionality]] (''"aboutness"''). [[phenomenology (psychology)|In psychology]], phenomenology largely has meant attempting to investigate consciousness using the method of [[introspection]], which means looking into one's own mind and reporting what one observes. This method fell into disrepute in the early twentieth century because of grave doubts about its reliability, but has been rehabilitated to some degree, especially when used in combination with techniques for examining brain activity.<ref>{{cite book |title=Trusting the Subject?: The Use of Introspective Evidence in Cognitive Science, Volume 1 |editors=Anthony Jack, Andreas Roepstorff |publisher=Imprint Academic |year=2003 |isbn=978-0-907845-56-0 |chapter=Valid and non-reactive verbalization of thoughts during performance of tasks: towards a solution to the central problems of introspection as a source of scientific evidence |author=[[K. Anders Ericsson]] |pages=1–18}}</ref>

[[File:Neon colour spreading illusion no caption.png|thumb|150px|right|[[Neon color spreading]] effect.  The apparent bluish tinge of the white areas inside the circle is an illusion.]][[File:Square neon spread.png|thumb|Square version of the neon spread illusion]]
Introspectively, the world of conscious experience seems to have considerable structure.  [[Immanuel Kant]] asserted that the world as we perceive it is organized according to a set of fundamental "intuitions", which include ''object'' (we perceive the world as a set of distinct things); ''shape''; ''quality'' (color, warmth, etc.); ''space'' (distance, direction, and location); and ''time''.<ref>{{cite web |title=Kant's view of the mind and consciousness of self |author=Andrew Brook |publisher=Stanford Encyclopedia of Philosophy |url=http://plato.stanford.edu/entries/kant-mind/#3.2.1}}  Note: translating Kant's terminology into English is often difficult.</ref> Some of these constructs, such as space and time, correspond to the way the world is structured by the laws of physics;  for others the correspondence is not as clear.  Understanding the physical basis of qualities, such as redness or pain, has been particularly challenging. David Chalmers has called this the ''[[hard problem of consciousness]]''.<ref name=ChalmersHardProblem /> Some philosophers have argued that it is intrinsically unsolvable, because qualities (''"[[qualia]]"'') are [[ineffability|ineffable]]; that is, they are "raw feels", incapable of being analyzed into component processes.<ref>{{cite book |chapter=On leaving out what it's like |author=[[Joseph Levine (philosopher)|Joseph Levine]] |title=The Nature of Consciousness: Philosophical Debates |editors=N. Block, O. Flanagan, G. Guzeldere |year=1998 |publisher=MIT Press |isbn=978-0-262-52210-6}}</ref> Most psychologists and neuroscientists reject these arguments. For example, research on [[ideasthesia]] shows that qualia are organised into a semantic-like network. Nevertheless, it is clear that the relationship between a physical entity such as light and a perceptual quality such as color is extraordinarily complex and indirect, as demonstrated by a variety of [[optical illusion]]s such as [[neon color spreading]].<ref>{{cite book |title=The Science of Color |editor=Steven K. Shevell |chapter=Color appearance |author=Steven K. Shevell |pages=149–190 |year=2003 |publisher=Elsevier |isbn=978-0-444-51251-2}}</ref>

In neuroscience, a great deal of effort has gone into investigating how the perceived world of conscious awareness is constructed inside the brain. The process is generally thought to involve two primary mechanisms: (1) hierarchical processing of sensory inputs, and (2) memory. Signals arising from sensory organs are transmitted to the brain and then processed in a series of stages, which extract multiple types of information from the raw input. In the visual system, for example, sensory signals from the eyes are transmitted to the [[thalamus]] and then to the [[primary visual cortex]]; inside the cerebral cortex they are sent to areas that extract features such as three-dimensional structure, shape, color, and motion.<ref name=BennettHacker>{{cite book |title=Philosophical Foundations of Neuroscience |authors=M. R. Bennett and Peter Michael Stephan Hacker |year=2003 |publisher=Wiley-Blackwell |isbn=978-1-4051-0838-6 |pages=121–147}}</ref> Memory comes into play in at least two ways. First, it allows sensory information to be evaluated in the context of previous experience. Second, and even more importantly, [[working memory]] allows information to be integrated over time so that it can generate a stable representation of the world—[[Gerald Edelman]] expressed this point vividly by titling one of his books about consciousness ''The Remembered Present''.<ref>{{cite book |author=[[Gerald Edelman]] |title=The Remembered Present: A Biological Theory of Consciousness |publisher=Basic Books |year=1989 |isbn=978-0-465-06910-1 |pages=109–118}}</ref> In computational neuroscience, [[Bayesian approaches to brain function]] have been used to understand both the evaluation of sensory information in light of previous experience, and the integration of information over time. Bayesian models of the brain are probabilistic inference models, in which the brain takes advantage of prior knowledge to interpret uncertain sensory inputs in order to formulate a conscious percept; Bayesian models have successfully predicted many perceptual phenomena in vision and the nonvisual senses.<ref>{{cite journal | author = Knill DC | year = 2007 | title = Learning Bayesian priors for depth perception | url = http://journalofvision.org//7/8/13/ | journal = Journal of Vision | volume = 7 | issue = 8| pages = 1–20 }}</ref><ref>{{cite journal |vauthors=Battaglia PW, Jacobs RA, Aslin RN | year = 2003 | title = Bayesian integration of visual and auditory signals for spatial localization | url = http://www.opticsinfobase.org/abstract.cfm?URI=josaa-20-7-1391 | journal = Journal of the Optical Society of America | volume = 20 | issue = 7| pages = 1391–7 | doi=10.1364/josaa.20.001391}}</ref><ref>{{cite journal|last=Goldreich|first=Daniel|author2=Tong, Jonathan|title=Prediction, Postdiction, and Perceptual Length Contraction: A Bayesian Low-Speed Prior Captures the Cutaneous Rabbit and Related Illusions|journal=Frontiers in Psychology|date=10 May 2013|volume=4|issue=221|doi=10.3389/fpsyg.2013.00221|url=http://www.frontiersin.org/consciousness_research/10.3389/fpsyg.2013.00221/abstract}}</ref>

Despite the large amount of information available, many important aspects of perception remain mysterious. A great deal is known about low-level signal processing in sensory systems, but the ways by which sensory systems interact with each other, with "executive" systems in the frontal cortex, and with the language system are very incompletely understood. At a deeper level, there are still basic conceptual issues that remain unresolved.<ref name=BennettHacker/>  Many scientists have found it difficult to reconcile the fact that information is distributed across multiple brain areas with the apparent unity of consciousness: this is one aspect of the so-called ''[[binding problem]]''.<ref>Koch, ''The Quest for Consciousness'', pp. 167–170</ref> There are also some scientists who have expressed grave reservations about the idea that the brain forms representations of the outside world at all: influential members of this group include psychologist [[James J. Gibson|J. J. Gibson]] and roboticist [[Rodney Brooks]], who both argued in favor of "intelligence without representation".<ref>{{cite journal |authors=[[Rodney Brooks]] |title=Intelligence without representation |year=1991 |journal=Artificial Intelligence |volume=47 |pages=139–159 |doi=10.1016/0004-3702(91)90053-M}}</ref>

==Medical aspects==
The medical approach to consciousness is practically oriented.   It derives from a need to treat people whose brain function has been impaired as a result of disease, brain damage, toxins, or drugs.  In medicine, conceptual distinctions are considered useful to the degree that they can help to guide treatments.   Whereas the philosophical approach to consciousness focuses on its fundamental nature and its contents, the medical approach focuses on the ''amount'' of consciousness a person has:  in medicine, consciousness is assessed as a "level" ranging from coma and brain death at the low end, to full alertness and purposeful responsiveness at the high end.<ref name=Blumenfeld>{{cite book |title=The Neurology of Consciousness: Cognitive Neuroscience and Neuropathology |editors=Steven Laureys, Giulio Tononi |chapter=The neurological examination of consciousness |author=Hal Blumenfeld |year=2009 |publisher=Academic Press |isbn=978-0-12-374168-4}}</ref>

Consciousness is of concern to patients and physicians, especially [[neurology|neurologists]] and [[anesthesia|anesthesiologists]]. Patients may suffer from disorders of consciousness, or may need to be anesthetized for a surgical procedure.  Physicians may perform consciousness-related interventions such as instructing the patient to sleep, administering [[general anesthesia]], or inducing [[induced coma|medical coma]].<ref name=Blumenfeld/> Also, [[bioethics|bioethicists]] may be concerned with the ethical implications of consciousness in medical cases of patients such as the [[Karen Ann Quinlan case]],<ref>{{cite journal|vauthors=Kinney HC, Korein J, Panigrahy A, Dikkes P, Goode R |date=26 May 1994|issue=21|journal=N Engl J Med|pages=1469–1475|pmid=8164698|title=Neuropathological findings in the brain of Karen Ann Quinlan -- the role of the thalamus in the persistent vegetative state|volume=330|doi=10.1056/NEJM199405263302101}}</ref> while neuroscientists may study patients with impaired consciousness in hopes of gaining information about how the brain works.<ref>Koch, ''The Quest for Consciousness'', pp. 216–226</ref>

===Assessment===
In medicine, consciousness is examined using a set of procedures known as [[neuropsychological assessment]].<ref name=Giacino>{{cite journal|author1=J. T. Giacino |author2=C. M. Smart |year=2007 |doi=10.1097/WCO.0b013e3282f189ef |journal=Current Opinion in Neurology |pages=614–619 |pmid=17992078 |title=Recent advances in behavioral assessment of individuals with disorders of consciousness |volume=20 |issue=6}}</ref>  There are two commonly used methods for assessing the level of consciousness of a patient: a simple procedure that requires minimal training, and a more complex procedure that requires substantial expertise.  The simple procedure begins by asking whether the patient is able to move and react to physical stimuli.  If so, the next question is whether the patient can respond in a meaningful way to questions and commands.  If so, the patient is asked for name, current location, and current day and time.  A patient who can answer all of these questions is said to be "alert and oriented times four" (sometimes denoted "A&Ox4" on a medical chart), and is usually considered fully conscious.<ref>{{cite book |title=Essentials of Abnormal Psychology |authors=V. Mark Durand and David H. Barlow |publisher=Cengage Learning |year=2009 |isbn=978-0-495-59982-1 |pages=74–75}}  Note: A patient who can additionally describe the current situation may be referred to as "oriented times four".</ref>

The more complex procedure is known as a [[neurological examination]], and is usually carried out by a [[neurology|neurologist]] in a hospital setting.  A formal neurological examination runs through a precisely delineated series of tests, beginning with tests for basic sensorimotor reflexes, and culminating with tests for sophisticated use of language.  The outcome may be summarized using the [[Glasgow Coma Scale]], which yields a number in the range 3—15, with a score of 3 to 8 indicating coma, and 15 indicating full consciousness.  The Glasgow Coma Scale has three subscales, measuring the ''best motor response'' (ranging from "no motor response" to "obeys commands"), the ''best eye response'' (ranging from "no eye opening" to "eyes opening spontaneously") and the ''best verbal response'' (ranging from "no verbal response" to "fully oriented").  There is also a simpler [[Paediatric Glasgow Coma Scale|pediatric]] version of the scale, for children too young to be able to use language.<ref name=Blumenfeld/>

In 2013, an experimental procedure was developed to measure degrees of consciousness, the procedure involving stimulating the brain with a magnetic pulse, measuring resulting waves of electrical activity, and developing a consciousness score based on the complexity of the brain activity.<ref name=NBCnews20130814>{{cite web |url=http://www.nbcnews.com/health/new-tool-peeks-brain-measure-consciousness-6C10919906 |title=New tool peeks into brain to measure consciousness |last=Neergaard |first=Lauren |date=August 14, 2013 |publisher=Associated Press through NBC News |archiveurl=http://www.webcitation.org/6IsYP826u |archivedate=August 14, 2013 }}</ref>

===Disorders of consciousness===
Medical conditions that inhibit consciousness are considered [[disorders of consciousness]].<ref name="chronic"/> This category generally includes [[minimally conscious state]] and [[persistent vegetative state]], but sometimes also includes the less severe [[locked-in syndrome]] and more severe [[coma|chronic coma]].<ref name="chronic">{{cite journal|author=Bernat JL|date=8 Apr 2006|doi=10.1016/S0140-6736(06)68508-5|issue=9517|journal=Lancet|pages=1181–1192|pmid=16616561|title=Chronic disorders of consciousness|volume=367}}
</ref><ref>{{cite journal|author=Bernat JL|date=20 Jul 2010|doi=10.1212/WNL.0b013e3181e8e960|issue=3|journal=Neurol|pages=206–207|pmid=20554939|title=The natural history of chronic disorders of consciousness|volume=75}}</ref> [[Differential diagnosis]] of these disorders is an active area of [[biomedical research]].<ref>{{cite journal|vauthors=Coleman MR, Davis MH, Rodd JM, Robson T, Ali A, Owen AM, Pickard JD |date=September 2009|doi=10.1093/brain/awp183|issue=9|journal=Brain|pages=2541–2552|pmid=19710182|title=Towards the routine use of brain imaging to aid the clinical diagnosis of disorders of consciousness|volume=132}}</ref><ref>{{cite journal|vauthors=Monti MM, Vanhaudenhuyse A, Coleman MR, Boly M, Pickard JD, Tshibanda L, Owen AM, Laureys S |date=18 Feb 2010|doi=10.1056/NEJMoa0905370|issue=7|journal=N Engl J Med|pages=579–589|pmid=20130250|title=Willful modulation of brain activity in disorders of consciousness|volume=362}}</ref><ref>{{cite journal|vauthors=Seel RT, Sherer M, Whyte J, Katz DI, Giacino JT, Rosenbaum AM, Hammond FM, Kalmar K, Pape TL |date=December 2010|doi=10.1016/j.apmr.2010.07.218|issue=12|journal=Arch Phys Med Rehabil|pages=1795–1813|pmid=21112421|title=Assessment scales for disorders of consciousness: evidence-based recommendations for clinical practice and research|volume=91|display-authors=etal}}</ref> Finally, [[brain death]] results in an irreversible disruption of consciousness.<ref name="chronic"/> While other conditions may cause a moderate deterioration (e.g., [[dementia]] and [[delirium]]) or transient interruption (e.g., [[tonic–clonic seizure|grand mal]] and [[absence seizure|petit mal seizures]]) of consciousness, they are not included in this category.

{| class="wikitable" style="width:100%"
|-
! Disorder !! Description
|-
| Locked-in syndrome || The patient has awareness, sleep-wake cycles, and meaningful behavior (viz., eye-movement), but is isolated due to [[quadriplegia]] and [[pseudobulbar palsy]].
|-
| Minimally conscious state || The patient has intermittent periods of awareness and wakefulness and displays some meaningful behavior.
|-
| Persistent vegetative state || The patient has sleep-wake cycles, but lacks awareness and only displays reflexive and non-purposeful behavior.
|-
| Chronic coma || The patient lacks awareness and sleep-wake cycles and only displays reflexive behavior.
|-
| Brain death || The patient lacks awareness, sleep-wake cycles, and brain-mediated reflexive behavior.
|}

===Anosognosia===
{{main|Anosognosia}}
One of the most striking disorders of consciousness goes by the name [[anosognosia]], a Greek-derived term meaning ''unawareness of disease''.  This is a condition in which patients are disabled in some way, most commonly as a result of a [[stroke]], but either misunderstand the nature of the problem or deny that there is anything wrong with them.<ref>{{cite book |editors=George Prigatano, [[Daniel Schacter]]|title=Awareness of Deficit After Brain Injury: Clinical and Theoretical Issues |publisher=Oxford University Press |year=1991 |chapter=Introduction |authors=George P. Prigatano and [[Daniel Schacter]]|pages=3–16 |isbn=0-19-505941-7}}</ref>  The most frequently occurring form is seen in people who have experienced a stroke damaging the [[parietal lobe]] in the right hemisphere of the brain, giving rise to a syndrome known as [[hemispatial neglect]], characterized by an inability to direct action or attention toward objects located to the right with respect to their bodies.  Patients with hemispatial neglect are often paralyzed on the right side of the body, but sometimes deny being unable to move.  When questioned about the obvious problem, the patient may avoid giving a direct answer, or may give an explanation that doesn't make sense.  Patients with hemispatial neglect may also fail to recognize paralyzed parts of their bodies:  one frequently mentioned case is of a man who repeatedly tried to throw his own paralyzed right leg out of the bed he was lying in, and when asked what he was doing, complained that somebody had put a dead leg into the bed with him.  An even more striking type of anosognosia is [[Anton–Babinski syndrome]], a rarely occurring condition in which patients become blind but claim to be able to see normally, and persist in this claim in spite of all evidence to the contrary.<ref>{{cite book |editors=George Prigatano, [[Daniel Schacter]]|title=Awareness of Deficit After Brain Injury: Clinical and Theoretical Issues |publisher=Oxford University Press |year=1991 |chapter=Anosognosia: possible neuropsychological mechanisms |authors=Kenneth M. Heilman|pages=53–62 |isbn=0-19-505941-7}}</ref>

==Stream of consciousness==
{{Main|Stream of consciousness (psychology)}}

[[William James]] is usually credited with popularizing the idea that human consciousness flows like a stream, in his ''Principles of Psychology'' of 1890.  According to James, the "stream of thought" is governed by five characteristics:  "(1) Every thought tends to be part of a personal consciousness. (2) Within each personal consciousness thought is always changing. (3) Within each personal consciousness thought is sensibly continuous. (4) It always appears to deal with objects independent of itself. (5) It is interested in some parts of these objects to the exclusion of others".<ref>{{cite book|authors=[[William James]] |title=The Principles of Psychology, Volume 1 |year=1890 |publisher=H. Holt |page=225}}</ref>  A similar concept appears in Buddhist philosophy, expressed by the Sanskrit term ''Citta-saṃtāna'', which is usually translated as [[mindstream]] or "mental continuum". Buddhist teachings describe that consciousness manifests moment to moment as sense impressions and mental phenomena that are continuously changing.<ref name=Aggregates>{{cite journal|author= Karunamuni N.D.|title=The Five-Aggregate Model of the Mind|journal=SAGE open|volume=5 |issue=2 |date=May 2015 | url= http://sgo.sagepub.com/content/spsgo/5/2/2158244015583860.full.pdf | doi=10.1177/2158244015583860}}</ref> The teachings list six triggers that can result in the generation of different mental events.<ref name="Aggregates"/> These triggers are input from the five senses (seeing, hearing, smelling, tasting or touch sensations), or a thought (relating to the past, present or the future) that happen to arise in the mind. The mental events generated as a result of these triggers are: feelings, perceptions and intentions/behaviour.  The moment-by-moment manifestation of the mind-stream is said to happen in every person all the time. It even happens in a scientist who analyses various phenomena in the world, or analyses the material body including the organ brain.<ref name="Aggregates"/> The manifestation of the mindstream is also described as being influenced by physical laws, biological laws, psychological laws, volitional laws, and universal laws.<ref name="Aggregates"/> The purpose of the Buddhist practice of [[mindfulness]] is to understand the inherent nature of the consciousness and its characteristics.<ref>{{cite book |title=Losing the Clouds, Gaining the Sky: Buddhism and the Natural Mind |chapter=Taming the mindstream |author=Dzogchen Rinpoche |editor=Doris Wolter |year=2007 |publisher=Wisdom Publications |isbn=978-0-86171-359-2 |pages=81–92}}</ref>

=== Narrative form ===

In the west, the primary impact of the idea has been on literature rather than science:  [[stream of consciousness (narrative mode)|stream of consciousness as a narrative mode]] means writing in a way that attempts to portray the moment-to-moment thoughts and experiences of a character.  This technique perhaps had its beginnings in the monologues of Shakespeare's plays, and reached its fullest development in the novels of [[James Joyce]] and [[Virginia Woolf]], although it has also been used by many other noted writers.<ref>{{cite book|authors=Robert Humphrey |title=Stream of Consciousness in the Modern Novel |year=1954 |publisher=University of California Press |isbn=978-0-520-00585-3 |pages=23–49}}</ref>

Here for example is a passage from Joyce's [[Ulysses (novel)|Ulysses]] about the thoughts of Molly Bloom:

{{quote|Yes because he never did a thing like that before as ask to get his breakfast in bed with a couple of eggs since the City Arms hotel when he used to be pretending to be laid up with a sick voice doing his highness to make himself interesting for that old faggot Mrs Riordan that he thought he had a great leg of and she never left us a farthing all for masses for herself and her soul greatest miser ever was actually afraid to lay out 4d for her methylated spirit telling me all her ailments she had too much old chat in her about politics and earthquakes and the end of the world let us have a bit of fun first God help the world if all the women were her sort down on bathingsuits and lownecks of course nobody wanted her to wear them I suppose she was pious because no man would look at her twice I hope Ill never be like her a wonder she didnt want us to cover our faces but she was a welleducated woman certainly and her gabby talk about Mr Riordan here and Mr Riordan there I suppose he was glad to get shut of her.<ref>{{cite book| authors=[[James Joyce]] |title=Ulysses |year=1990 |publisher=BompaCrazy.com |page=620}}</ref>}}

==Spiritual approaches==
{{Further|Level of consciousness (esotericism)|Higher consciousness}}
To most philosophers, the word "consciousness" connotes the relationship between the mind and the world. To writers on spiritual or religious topics, it frequently connotes the relationship between the mind and God, or the relationship between the mind and deeper truths that are thought to be more fundamental than the physical world.  [[International Society for Krishna Consciousness|Krishna consciousness]], for example, is a term used to mean an intimate linkage between the mind of a worshipper and the god Krishna.<ref>{{cite book |author=Lynne Gibson |title=Modern World Religions: Hinduism |publisher=Heinemann Educational Publishers |year=2002 |isbn=0-435-33619-3|pages=2–4}}</ref>  The mystical psychiatrist [[Richard Maurice Bucke]] distinguished between three types of consciousness:  ''Simple Consciousness'', awareness of the body, possessed by many animals; ''Self Consciousness'', awareness of being aware, possessed only by humans; and ''Cosmic Consciousness'', awareness of the life and order of the universe, possessed only by humans who are enlightened.<ref>{{cite book |authors=[[Richard Maurice Bucke]]|title=Cosmic Consciousness: A Study in the Evolution of the Human Mind |publisher=Innes & Sons |year=1905 |url=https://books.google.com/books?id=gxRWAAAAMAAJ |pages=1–2}}</ref>  Many more examples could be given. The most thorough account of the spiritual approach may be [[Ken Wilber]]'s book ''The Spectrum of Consciousness'', a comparison of western and eastern ways of thinking about the mind.  Wilber described consciousness as a spectrum with ordinary awareness at one end, and more profound types of awareness at higher levels.<ref>{{cite book |authors=[[Ken Wilber]] |title=The Spectrum of Consciousness |publisher=Motilal Banarsidass Publ. |year=2002 |isbn=978-81-208-1848-4|pages=3–16}}</ref>

==See also==
{{Portal|Medicine|Mind and Brain|Philosophy}}
{{div col||20em}}
* [[Antahkarana]]
* [[Being]]
* [[Blindsight]]
* [[Causality]]
* [[Centipede's dilemma]]
* [[Cognitive closure (philosophy)|Cognitive closure]]
* [[Cognitive neuroscience]]
* [[Cognitive psychology]]
* [[Chaitanya (consciousness)]]
* [[Id, ego and super-ego#Ego|Ego]]
* [[Episodic memory]]
* [[Explanation]]
* [[Explanatory gap]]
* [[Functionalism (philosophy of mind)]]
* [[Hard problem of consciousness]]
* [[Ideasthesia]]
* [[Merkwelt]]
* [[Mind–body problem]]
* [[Mirror neuron]]
* [[Modularity of mind]]
* [[Neural correlates of consciousness]]
* [[Neuropsychological assessment]]
* [[Neuropsychology]]
* [[New mysterianism]]
* [[Orch-OR]]
* [[Phenomenology (philosophy)|Phenomenology]]
* [[Philosophical zombie]]
* [[Philosophy of mind]]
* [[Problem of other minds]]
* [[Quantum mind]]
* [[Reentry (neural circuitry)]]
* [[Reverse engineering]]
* [[Sentience]]
* [[Solipsism]]
* [[Soul]]
* [[Spirit]]
* [[Stream of consciousness (psychology)]]
* [[Turing test]]
* [[Unconsciousness]]
{{div col end}}

==References==
{{Research help|Med}}
{{Reflist|30em}}

==Further reading==
* {{cite book|author=Antonio Damasio|title=Self Comes to Mind: Constructing the Conscious Brain|year=2012|publisher=Vintage|isbn=978-0307474957}}
* {{cite book|author1=Philip David Zelazo |author2=Morris Moscovitch |author3=Evan Thompson |title=The Cambridge Handbook of Consciousness|year=2007|publisher=Cambridge University Press|isbn=978-0-521-67412-6}}

==External links==
{{wikiquote}}
{{Library resources box|by=no|onlinebooks=no|about=yes|wikititle=consciousness}}
* {{Wiktionary-inline|consciousness}}
* {{Wikibooks-inline|Consciousness Studies}}
* {{cite SEP |url-id=conscience |title=Conscience |last=Giubilini |first=Alberto}}
*{{cite SEP |url-id=consciousness |title=Consciousness |last=Gulick |first=Robert Van}}
* {{cite IEP |url-id=consciou |title=Consciousness}}
* {{DMOZ|Society/Philosophy/Philosophy_of_Mind/Consciousness_Studies/}}
* [http://www.elsevier.com/wps/find/journaldescription.cws_home/622810/description#description ''Consciousness and Cognition'']
* [http://www.ingentaconnect.com/content/jbp/ce ''Consciousness & Emotion'']
* [http://www.imprint.co.uk/jcs.html ''Journal of Consciousness Studies'']

{{Footer Neuropsychology}}
{{Philosophy of mind}}
{{Psychophysiology}}
{{Mental processes}}

{{Authority control}}

[[Category:Cognition]]
[[Category:Cognitive neuroscience]]
[[Category:Cognitive psychology]]
[[Category:Consciousness| ]]
[[Category:Mental processes]]
[[Category:Neuropsychological assessment]]
[[Category:Neuropsychology]]
[[Category:Phenomenology]]